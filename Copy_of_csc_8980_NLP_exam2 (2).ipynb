{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_csc_8980_NLP_exam2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBFzj2JnUijP"
      },
      "source": [
        "## Rajath Chikkatur Srinivasa\n",
        "## 002552425"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trKZNVGwUlFp"
      },
      "source": [
        "# imports\n",
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk, os\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# importing required libraries\n",
        "import re, random, os, nltk,spacy, os, time, datetime\n",
        "# from collections import Counter, defaultdict\n",
        "import seaborn as sns\n",
        "from nltk import bigrams, trigrams\n",
        "# all sklearn imports\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.tokenize import word_tokenize\n",
        "# import nltk\n",
        "# nltk.download('punkt')\n",
        "# importing models\n",
        "#importing classifier types\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import make_pipeline\n",
        "#importing metrics\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "import os\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from numpy import array\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "import torch\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "#installs\n",
        "!pip install wget\n",
        "!pip install transformers\n",
        "clear_output()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YRiWp9VqeO_-",
        "outputId": "a76fcaf9-2b6b-4c49-a781-3aba8820314e"
      },
      "source": [
        "# mounting Gdrive, please authenticate with the ID\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "H_hmuqe9qB5f",
        "outputId": "cde775bd-f38d-4f5e-dc0c-7b29d8c749c1"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4SrYtF_sVc0"
      },
      "source": [
        "### Question 1) (20 points) Write a function that takes a List of five words: [‘apple’, ‘house’, ‘pear’, ‘dog’, ‘doctor’] and returns a list of lists with each element being a word and a list of the top five most similar words. For this task you have to use the most suitable method of the ones we have seen in class to determine the most similar words to the original input list. You can use a pre-trained resource if you think is appropriate. After calling your function, print the most similar words to the screen. Are these ‘similar’ words actually similar? If not, why not? What do you think can be improved and how - talk about it, do not necessarily implement it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "adUFH_ZivKO4",
        "outputId": "3adba169-237a-4960-eaaf-b95aa0eefdc2"
      },
      "source": [
        "# Google's Word2Vec pre-computed embedding\n",
        "!gdown --id 1Qw8q4EKeQMahUaZasX_quuBtqDPeJTH0\n",
        "# gunzip the contents of the embeddings file.\n",
        "!gunzip /content/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Qw8q4EKeQMahUaZasX_quuBtqDPeJTH0\n",
            "To: /content/GoogleNews-vectors-negative300.bin.gz\n",
            "1.65GB [00:31, 52.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GcMOjb8NGz_N",
        "outputId": "67fe690d-8f98-41a9-9aa3-5fbd4322cd66"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkFz0bEH_4jk"
      },
      "source": [
        "# In order to load the downloaded embeddings, we need to use gensim's KeyedVectors\n",
        "filename = '/content/GoogleNews-vectors-negative300.bin'\n",
        "# taking a lot of time hence placing in new cell text\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True, datatype=np.float16)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsE7Ir84sa42"
      },
      "source": [
        "def listoflist(list_of_five_words):\n",
        "  # final list containing another list in its last element which contains top five similar terms\n",
        "  comparison = []\n",
        "  for i in list_of_five_words:\n",
        "    firstlist = [i]\n",
        "    topfive = model.most_similar(i)[:5]\n",
        "    secondlist = [j[0] for j in topfive] # topfive = topfive[:5]\n",
        "    firstlist.append(secondlist) # making list of list\n",
        "    comparison.append(firstlist) # final set of list of list is appended to a list\n",
        "  return comparison"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVs8wHev3e13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "18a5557b-a1ad-4c8d-da3c-794ed2bd07e9"
      },
      "source": [
        "# driver code\n",
        "# listoflist(['apple', 'house', 'pear', 'dog', 'doctor'])\n",
        "test = ['apple', 'house', 'pear', 'dog', 'doctor']\n",
        "listoflist(test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['apple', ['apples', 'pear', 'fruit', 'berry', 'pears']],\n",
              " ['house', ['houses', 'bungalow', 'apartment', 'bedroom', 'townhouse']],\n",
              " ['pear', ['pears', 'apricot', 'apricots', 'nectarine', 'Fuji_apple']],\n",
              " ['dog', ['dogs', 'puppy', 'pit_bull', 'pooch', 'cat']],\n",
              " ['doctor', ['physician', 'doctors', 'gynecologist', 'surgeon', 'dentist']]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "543T7DdLsyRK"
      },
      "source": [
        "### Question 2) (30 points) Using the Homework 2 dataset, also attached in the Exam 2 files, shakespeares-works_TXT_FolgerShakespeare.zip. Find the document to document similarity using: \n",
        "#### a) Cosine similarity. And create a 42 x 42 heatmap of these similarities. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xZYyLWzDDtG"
      },
      "source": [
        "!unzip /content/drive/MyDrive/NLP/shakespeares-works_TXT_FolgerShakespeare.zip\n",
        "clear_output()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "dtsVyy3qtAP5",
        "outputId": "5aaa6f72-1c0c-487f-db30-a0919344eb81"
      },
      "source": [
        "folder_path = '/content/shakespeares-works_TXT_FolgerShakespeare/Shakespeare'\n",
        "file_content_corpus = []\n",
        "filenames = []\n",
        "for i in os.listdir(folder_path):\n",
        "  if not i.startswith('__'):\n",
        "    filenames.append(i)\n",
        "    file_content = open(os.path.join(folder_path,i), 'r').read()\n",
        "    file_content_corpus.append(file_content)\n",
        "# file_content_corpus = \" \".join(file_content_corpus)\n",
        "\n",
        "vec = TfidfVectorizer()\n",
        "X = vec.fit_transform(file_content_corpus)\n",
        "cos_s = cosine_similarity(X, X)\n",
        "plt.imshow(cos_s)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff95bf809d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kA00ZpLLIauM"
      },
      "source": [
        "#### b) Use Doc2Vec to create document embeddings and find the similarities between the documents. To visualize this, also create a 42 x 42 heatmap for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "5HQ4bmI-t_Rx",
        "outputId": "768a1217-fc39-4983-ba61-5c0911f86019"
      },
      "source": [
        "model = Doc2Vec(vector_size=50, min_count=2, epochs=40)\n",
        "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower()), tags=[str(i)]) for i, _d in enumerate(file_content_corpus)]\n",
        "\n",
        "max_epochs, mxm = 50, 42\n",
        "\n",
        "model = Doc2Vec(size=50, alpha=0.025, min_alpha=0.00025,min_count=1,dm =1)\n",
        "  \n",
        "model.build_vocab(tagged_data)\n",
        "\n",
        "for epoch in range(50):\n",
        "    model.train(tagged_data,total_examples=model.corpus_count,epochs=model.iter)\n",
        "    model.alpha -= 0.0002\n",
        "    model.min_alpha = model.alpha\n",
        "\n",
        "# creating a 42 cross 42 matrix of 1s\n",
        "cos_s = []\n",
        "for i in range(mxm):\n",
        "    cos_s.append([])\n",
        "    for j in range(mxm):\n",
        "        cos_s[i].append(1)\n",
        "\n",
        "for i in range(mxm):\n",
        "  similarity1 = model.docvecs.most_similar(i,topn=42)\n",
        "  for j in similarity1:\n",
        "    islice = int(j[0])\n",
        "    cos_s[i][islice] = j[1]\n",
        "\n",
        "plt.imshow(cos_s)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7ff95427df10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "i2tiNTdBMk1H",
        "outputId": "9885f3d4-85e7-4062-a601-d1663d236c79"
      },
      "source": [
        "similarity = model.docvecs.most_similar('1',topn=42)\n",
        "similarity = sorted(similarity)\n",
        "print('The similarity score for each each document is')\n",
        "for i in similarity:\n",
        "  print(i)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The similarity score for each each document is\n",
            "('0', 0.21317525207996368)\n",
            "('10', 0.32071197032928467)\n",
            "('11', 0.4520968496799469)\n",
            "('12', 0.38873761892318726)\n",
            "('13', 0.34445664286613464)\n",
            "('14', 0.3373895585536957)\n",
            "('15', 0.3161478638648987)\n",
            "('16', 0.1570507436990738)\n",
            "('17', 0.11829528212547302)\n",
            "('18', 0.4530378580093384)\n",
            "('19', 0.29758116602897644)\n",
            "('2', 0.4226939082145691)\n",
            "('20', 0.0777827724814415)\n",
            "('21', 0.17364826798439026)\n",
            "('22', 0.1568813920021057)\n",
            "('23', 0.3616968095302582)\n",
            "('24', 0.34042978286743164)\n",
            "('25', 0.3123493194580078)\n",
            "('26', 0.24462229013442993)\n",
            "('27', 0.22141726315021515)\n",
            "('28', 0.24261243641376495)\n",
            "('29', 0.28316381573677063)\n",
            "('3', 0.3032825291156769)\n",
            "('30', 0.02393375337123871)\n",
            "('31', 0.36235252022743225)\n",
            "('32', 0.28563550114631653)\n",
            "('33', 0.12910181283950806)\n",
            "('34', 0.3440837264060974)\n",
            "('35', 0.2711251974105835)\n",
            "('36', 0.1974915713071823)\n",
            "('37', 0.3304848372936249)\n",
            "('38', 0.3610646426677704)\n",
            "('39', 0.047860078513622284)\n",
            "('4', 0.2296040952205658)\n",
            "('40', 0.23974323272705078)\n",
            "('41', 0.16379117965698242)\n",
            "('5', 0.370618999004364)\n",
            "('6', 0.41760921478271484)\n",
            "('7', 0.4614565670490265)\n",
            "('8', 0.2953251600265503)\n",
            "('9', 0.2622063457965851)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fai_jOZ2ISNq"
      },
      "source": [
        "#### c) What are the differences you find between the two methods? Is there anything radically different? Please describe your answer in terms of the heatmap of part a and part b.\n",
        "- This is a radical change. The heatmap of Doc2Vec is more dense meaning the similarity score measure depicted by Doc2Vec is much precise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK_vCfLrHvLd"
      },
      "source": [
        "### Question 3) (30 points) Using the Homework 2 dataset. Use SpaCy to extract the following: \n",
        "\n",
        "### d) What do you think the most common bigrams and trigrams could be useful for? There is a particular method we have seen in this class to characterize a corpus that could benefit from having these bigrams/trigrams when the underlying text corpus can’t be shared. Please talk about this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZmf71WYff9D"
      },
      "source": [
        "!unzip /content/drive/MyDrive/Projects/NLP/shakespeares-works_TXT_FolgerShakespeare.zip\n",
        "clear_output()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ym9t5lcIM-n5"
      },
      "source": [
        "folder_path = '/content/shakespeares-works_TXT_FolgerShakespeare/Shakespeare'\n",
        "file_content_corpus = []\n",
        "filenames = []\n",
        "for i in os.listdir(folder_path):\n",
        "  if not i.startswith('__'):\n",
        "    filenames.append(i)\n",
        "    file_content = open(os.path.join(folder_path,i), 'r').read()\n",
        "    file_content_corpus.append(file_content)\n",
        "file_content_corpus = \" \".join(file_content_corpus)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRfXx71wi5e3"
      },
      "source": [
        "nlp.max_length = 60000000\n",
        "doc = nlp(file_content_corpus)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSiEx0s1ZzRn"
      },
      "source": [
        "### a) Write a function to generate all unique bigrams from all documents in the dataset. The input of this function should be the concatenated dataset and the output should be the list of bigrams and their frequency. Display the top 10 most common bigrams and their frequency"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUyLGb4hVxY2"
      },
      "source": [
        "def unique_bigrams(dataset):\n",
        "  bigramlist = []\n",
        "  doc = nlp(dataset)\n",
        "  bigramList, sentence = [], []\n",
        "  for token in doc:\n",
        "    if token.is_alpha:\n",
        "      sentence.append(token)\n",
        "  for word in range(len(sentence) - 1):\n",
        "    first_word = sentence[word]\n",
        "    second_word = sentence[word + 1]\n",
        "    element = [first_word, second_word]\n",
        "    bigramList.append(element)\n",
        "  print(bigramList)\n",
        "  bidict = {}\n",
        "  bigram_new = []\n",
        "  for i in bigramList:\n",
        "      j = \"\".join(str(i))\n",
        "      bigram_new.append(j)\n",
        "  for i in bigram_new:\n",
        "      if i in bidict:\n",
        "          bidict[i]+=1\n",
        "      else:\n",
        "          bidict[i]=1\n",
        "  return list(bidict.items())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkKwvQqfL952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d5fc0fa7-08bc-4d2c-fd67-61ce75ea689c"
      },
      "source": [
        "# function call / output\n",
        "# unique_bigrams()\n",
        "toptenB = sorted(unique_bigrams('file_content_corpus of no where partying in tennessene and i came back')[:10])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[of, no], [no, where], [where, partying], [partying, in], [in, tennessene], [tennessene, and], [and, i], [i, came], [came, back]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('[no, where]', 1), ('[of, no]', 1)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09DEd0c1MLY4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "248d3957-f8a3-4460-c7c2-baf88c770f7d"
      },
      "source": [
        "print(\"Ten most common bigrams with their frequency are {} \".format(toptenB))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ten most common bigrams with their frequency are [('[no, where]', 1), ('[of, no]', 1)] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5u-uq2PfoGf"
      },
      "source": [
        "### b) Write a function to generate all unique trigrams from all documents in the dataset. The input of this function should be the concatenated dataset and the output should be the list of trigrams and their frequency. Display the top 10 most common trigrams and their frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGPv-e2_fojC"
      },
      "source": [
        "def unique_trigrams(dataset):\n",
        "  trigramlist = []\n",
        "  doc = nlp(dataset)\n",
        "  trigramlist, sentence = [], []\n",
        "  for token in doc:\n",
        "    if token.is_alpha:\n",
        "      sentence.append(token)\n",
        "  for word in range(len(sentence) - 1):\n",
        "    first_word = sentence[word]\n",
        "    second_word = sentence[word + 1]\n",
        "    third_word = sentence[word + 2]\n",
        "    element = [first_word, second_word, third, third_word]\n",
        "    trigramlist.append(element)\n",
        "  print(trigramlist)\n",
        "  tridict = {}\n",
        "  trigram_new = []\n",
        "  for i in trigramlist:\n",
        "      j = \"\".join(str(i))\n",
        "      trigram_new.append(j)\n",
        "  for i in trigram_new:\n",
        "      if i in tridict:\n",
        "          tridict[i]+=1\n",
        "      else:\n",
        "          tridict[i]=1\n",
        "  return list(tridict.items())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMt1xmG9gCg5"
      },
      "source": [
        "toptenT = sorted(unique_trigrams(file_content_corpus)[:10])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptD4e7KigIs2"
      },
      "source": [
        "print(\"Ten most common trigrams with their frequency are {} \".format(toptenT))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24iWgjoigGzL"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixcL3CcMlepM"
      },
      "source": [
        "### c) Write a function to extract all unique NOUN and VERB tokens. The input of this function should be the concatenated dataset and the output should be two lists: one of the NOUN tokens and their frequency, the other list should be the VERB tokens and their counts. Display the top 10 most common NOUN and VERB tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zofpSe8Ylhux"
      },
      "source": [
        "def extractNV(dataset):\n",
        "  nlp.max_length = 60000000\n",
        "  doc = nlp(dataset)\n",
        "  v_count, n_count = 0,0\n",
        "  verb_tokens, noun_tokens = {}, {}\n",
        "  for i in doc:\n",
        "    if i.pos_=='VERB':\n",
        "      if i in verb_tokens:\n",
        "        verb_tokens[i.text]+=1\n",
        "      else:\n",
        "        verb_tokens[i.text]=1\n",
        "    elif i.pos_=='NOUN':\n",
        "      if i in noun_tokens:\n",
        "        noun_tokens[i.text]+=1\n",
        "      else:\n",
        "        noun_tokens[i.text]=1\n",
        "  return list(verb_tokens.items()), list(noun_tokens.items())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RGkYMisNYpMA",
        "outputId": "947b6b09-bbe3-4f1a-9fcb-a441db1a7480"
      },
      "source": [
        "print(extractNV(file_content_corpus))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([('Edited', 1), ('Created', 1), ('dedicate', 1), ('beginning', 1), ('makes', 1), ('assured', 1), ('done', 1), ('devoted', 1), ('would', 1), ('show', 1), ('bound', 1), ('wish', 1), ('lengthened', 1), ('surnamed', 1), ('caused', 1)], [('version', 1), ('love', 1), ('Lordship', 1), ('end', 1), ('pamphlet', 1), ('moiety', 1), ('warrant', 1), ('disposition', 1), ('worth', 1), ('lines', 1), ('acceptance', 1), ('yours', 1), ('part', 1), ('duty', 1), ('life', 1), ('happiness', 1), ('ARGUMENT', 1), ('pride', 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laNlKMrsZFWl"
      },
      "source": [
        "### d) What do you think the most common bigrams and trigrams could be useful for? There is a particular method we have seen in this class to characterize a corpus that could benefit from having these bigrams/trigrams when the underlying text corpus can’t be shared. Please talk about this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX5ys-1LScnY"
      },
      "source": [
        "### Question 4) (30 points) Using the dataset: Ask0729, found in Exam files, write two functions to extract all dates found in this dataset. The input of these functions should take the dataset as input, and output a list of dates. You should use two different methods, one per function.  \n",
        "### a) First method: using SpaCy (this is a big enough hint)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ueOTsO9fSlh7",
        "outputId": "86d59cf7-237f-4b14-a8b9-f2b396da8a62"
      },
      "source": [
        "ask = open('Ask0729-fixed.txt', 'r')\n",
        "ask = ask.read()\n",
        "def date_extract(dataset):\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  doc = nlp(dataset)\n",
        "  datelist = []\n",
        "  for i in doc.ents:\n",
        "     if i.label_ == 'DATE':\n",
        "       datelist.append(i.text)\n",
        "  return datelist\n",
        "date = date_extract(ask)\n",
        "# sample output\n",
        "date[:5], len(date)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['up to 5 years', 'today', 'today', 'today', 'one week'], 1033)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGL1izthS3LD"
      },
      "source": [
        "### b) Second method: using regular expressions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7CHRayNS5Ak"
      },
      "source": [
        "def date_extract_re(dataset):\n",
        "  datex = r'(?:\\d{1,2}[-/th|st|nd|rd\\s.])?(?:(?:Jan|January|Feb|February|Mar|March|Apr|April|May|Jun|June|Jul|July|August|Sep|September|Oct|October|Nov|November|Dec|December)[\\s,.])?(?:(?:\\d{1,2})[-/th|st|nd|rd\\s,.])?(?:\\d{2,4})'\n",
        "  datematch = re.findall(datex, ask)\n",
        "  return datematch"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vakN4LDMTGGe"
      },
      "source": [
        "### c) Print to screen to compare the results from the two functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0EwgvpkNTI9B",
        "outputId": "a83fbeba-fc69-498f-fc1f-4857a6c7d652"
      },
      "source": [
        "# result from first function\n",
        "print(date_extract(ask))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['up to 5 years', 'today', 'today', 'today', 'one week', 'MA 02143', 'daily', 'today', '3+ Nights & Save', 'this week', 'weekend', 'this week', '2 Weeks', 'the year', 'tomorrow', 'Wednesday', 'Saturday', 'the 6 year old', 'tomorrow', '25 years', 'year end 2000', 'under 40/over 40', 'junior-year', 'all summer', 'next week', 'yesterday', 'Monday', 'Thursday 4:00PM', 'July 31, 2014', '30 June 2012', 'April 15th', 'this year', 'this time', 'next year', 'years', 'Friday', 'Monday', 'December 7th', 'yesterday', 'yesterday', 'tomorrow', '14 day', '2 days', 'years', 'tomorrow', 'tomorrow', 'tomorrow', 'the next year', 'Sunday', 'a day', '12 MONTHS', 'July 4, 2012', 'Tomorrow', 'this week', 'Tuesday, March 20, 2001', 'annual', '21st Century', 'this week', 'tomorrow', 'next Wednesday', 'the old days', 'Next week', 'April', 'the 19th', 'August 31st', 'the year', 'only a week', 'June 23, 2000', 'today', 'Last week', 'Friday', 'the week', 'the 31st of March', '1 Year Giveaway', 'Thanksgiving', 'Today', 'Tomorrow', '2 weeks ago', 'every day', 'weekly', 'annual', 'tomorrow', 'A few weeks ago', 'this week', '1999', '2000', 'annual', '2081', 'Monday', 'March 8, 2013', 'the late 18th century', 'last week', 'today', 'next week', 'Sunday', 'the next two weeks', 'a few weeks', 'today', '1850-1940 1.1.0', 'February 28, 2014', 'the last year', 'the weeks', 'months ahead', '2 day', 'today', '30 June', 'the next 75 days', '2000', 'about a month', \"last Tuesday'Wednesday's\", 'Thursday', 'this year', '11 July', '1 year', 'April 2011', 'Day 5', 'April 5-19 15,000/day', 'Wednesday, June 27', 'the first weekend', 'April', 'Jan 26th', 'the weekend', 'the week of January 15th', 'that week', 'friday', 'yesterday', 'Thursday', 'approximately 2 years', 'the next 3-6 months', 'yesterday', 'August 2013', 'August 22, 2012', 'August 23, 2012', 'August 8, 2012', 'this Monday, September 2nd, 2013', 'a week or so ago', 'Friday', '2001', 'today', 'tomorrow', 'last week', 'tomorrow', 'yesterday', 'Monday', 'Tuesday', 'the days/weeks ahead', 'Thursday', '36 months', 'Wednesday', 'Thursday', 'Tuesday, October 24 - available 9:30 am to 1:00 pm', 'daily', 'August', \"Dec. '95\", \"Dec. '95\", 'today', 'tomorrow', 'Wednesday, July 31, 2013', 'the 16th of August', 'Monday, January 14, 2013', 'Friday', 'Friday', 'the first two days', '17 days ago', 'Nov. 8, 2000', 'today', 'the end of the month', 'five-year', 'May 16th', '7', 'quarterly', 'April 16', '2001', 'the school year', 'Weekly', 'Monday, April 23rd', 'Weekly', 'Monday, January 29', 'Thursday, June 14, 2001', 'St 65', 'Friday', 'Friday', 'Friday', 'Christmas', 'July', 'tomorrow', 'tomorrow', 'August', 'the week of April 16', 'April 16, 17', '18 or 19th', 'today', 'Thursday', 'tomorrow', 'today', 'the 13th and 14th', 'tomorrow', 'Monday', 'another month', 'weeks', 'mid-May', 'today', 'tomorrow', 'this week', 'next week', 'this week', 'the day', 'tomorrow', 'today', 'this weeks', 'Monday', 'the past few winters', 'tomorrow', 'tomorrow', 'today', 'tomorrow', 'this week', 'next week', 'next week', 'early November', 'tomorrow', 'this season', 'yesterday', 'a day', 'days', 'today', 'quarter this year', 'Monday', 'Tuesday', 'Monday', 'tomorrow', 'Thursday', 'today', 'tomorrow', 'Tuesday', 'today', 'next week', 'several business days', 'today', 'today', 'half days', 'next week', 'tomorrow', 'Wed of next week', 'this summer', 'Nov. 29', 'a couple of weeks', 'today', 'yesterday', 'Wednesday, October 25', 'later this week', 'next week', 'the day', 'tomorrow - deal 169576', 'tomorrow', 'last year', 'Friday', 'July', 'no quarter', 'the next 60-90 days', 'one month', 'today', 'last week', 'today', 'this week', 'all day', 'tomorrow', 'next week', 'the week', 'tomorrow', 'about 10 days', 'this week', 'today', 'February', 'monthly', 'next week', 'every day', 'the next couple of hours', 'Friday', 'end of day', 'today', 'Monday', 'tomorrow', 'Monday', 'today', 'today', '9 years', 'the next ten days', 'January', 'December', 'daily', 'GoHealthInsurance', 'January 16, 2013 to January 18, 2013', 'today', '10010', 'the end of April', 'tomorrow', 'two year', 'this year', 'monthly', 'every month', 'this month', '2 Weeks', 'the 13th', 'the 12th', 'the weeks', 'today', 'Halloween', 'next week', 'December', 'NaNoWriMo 2013', 'the last 6 months', 'each day', 'Monday', 'Wednesday', 'this week', 'July', 'June 2011 13', 'Day 5', 'June', 'an awesome month', 'the last several months', 'Thursday', 'the weekend', 'daily', 'Half-Year', 'July 11', '380571', 'LAST DAY', 'LAST DAY', 'Last Week', 'Last year', 'every week', 'Wednesday', 'Saturday', 'the 14th of May.', 'a week', 'Aug. 3, 2000', 'March 2011 12: Period Day 1 13:', '7 28', 'Day 1', 'Wednesday, December 31st', 'Monday', 'Monday', 'Monday through Friday', 'Monday, April 16th', 'Monday, August 6th', 'Monday, June 4th', 'Monday', 'May 14th', 'this week', 'several weeks ago', 'Feb. 20, 2001', 'Tuesday', 'the first quarter', 'January', 'today', 'this week', 'Feb 26, 2013', 'Friday, October 26, 2001', 'July 3, 2012', 'May 3rd', 'November 3', 'the days', 'Saturday', '30 days', 'One Week to Christmas', 'One day', 'Friday, May 25', 'tomorrow', 'the last several years', 'a few weeks ago', 'Monday', 'Tuesday, October 2 4, 2000', '1 year', 'the week of the 11th', 'tomorrow', 'Monday', 'monthly', 'today', 'Friday', 'Tuesday, June 12, 2001', '7 days', 'every month', 'Thursday', 'next week', 'Saturday', 'HE15-19', 'Monday', 'next week', 'Friday', 'Saturday January 19, 2002', 'Saturday', 'Monday', 'Sunday', 'Friday, April the 27th', 'Monday', 'tomorrow', 'tomorrow', 'last Thursday', 'September 4, 2011', 'Wednesday', 'the fall', 'Thursday', 'Sunday 28 August 2011', 'hundreds of years ago', 'the football season', 'tomorrow', 'yesterday', 'this year', 'tomorrow', 'Tomorrow', 'August 21, 2001', 'next summer', 'today', 'tomorrow', 'today', 'Monday, December 16th, 2013', 'tomorrow', 'Friday the 15th', 'Nov. 15th', 'Dec. 1', 'Wednesday', 'Wednesday', 'this week', 'Friday', 'next week', 'this week', 'yesterday', 'tomorrow', 'tomorrow', 'tomorrow', 'Wednesday', '33462', '33464', '33491', '33492', 'Feb. 8', 'Wednesday, August 28th', 'yesterday', 'the end of next week', 'August 18th', 'Sunday, July 14th', 'Four Weeks', '4 Weeks', '1-Hour', 'a day', 'next day', 'nightly', 'tomorrow', '2001', 'April 2010', 'this week', 'Sunday', 'tomorrow', 'today', '1989', '1989', 'October 17, 2013', 'tomorrow', 'next week', 'next week', 'This Friday', 'Saturday', '251415618', 'today', 'Friday', 'July 28 - August 4, 2001', 'every single day', 'the weekend', 'summer', 'This month', 'later this quarter', 'This week', '72', 'This week', 'Halloween', 'This week', 'This weekend', '2001', '2001', 'This year', 'today', '3:45pm - 10:00pm', 'Today', 'Today', 'Today', 'Today', 'Today', 'Today', 'Tomorrow', 'Wednesday', 'Thursday', 'Friday', 'Tomorrow', 'this week', 'year 2001', 'this week', 'today', 'Two Weeks', 'the next couple of weeks', 'this summer', '6 years', 'Thursday', 'Thursday & Friday', 'Thursday, January 25, 2001 08:36 AM?ET', 'Sept. 11', 'Thursday, September 19th', 'each day', 'daily', 'Saturday', 'between the days', 'July', 'Friday', 'Thursday', 'today', 'tomorrow', 'Thursday', 'later this week', 'this month', 'daily', 'monthly', 'this week', 'next week', 'Wednesday', '01&prudent', 'the past few months', \"this current year's\", 'a couple of days', 'Thursday', '2014-07-01', 'this week', 'next week', 'Wednesday', 'Labor Day', 'Friday of this week', 'Monday', 'this weekend', 'Monday 5 November', '19.30', '1201', '7 FREE days', 'this day', 'tomorrow', 'these last few weeks', 'Wednesday, August 2nd', 'last week', 'January', 'the new day', 'summer', 'maybe weeks', 'the coming decade', 'the coming decade', 'year', 'winter', 'the coming year', 'the next 3 business days', 'four weeks', 'the winter', 'the next week', 'Tuesday', 'a couple of weeks', 'tomorrow', 'daily', '1 Dec 2013', '30 day', 'Sunday 29 April 2012', 'January 31, 2013', 'Monday', 'today', 'today', 'Thursday, 31st January', 'the 29th', 'this week', 'today', 'today', 'Tuesday', 'each day', 'this week', 'may 1', 'may 2', '978/281-0744', '2 weeks', 'next week', 'Sept. 11', 'today', 'yesterday', 'weekly', '7 days', 'tomorrow', 'Sunday', 'another 30 days', 'Friday', 'Friday', 'Thursday June 20', 'January', 'Monday, October 8, 2001', 'the month of November', 'Sept. 20', 'tomorrow', 'Thursday', 'Friday', 'today', 'Sunday, December 8th, 2013', 'Monday, November 11th', 'Wednesday, September 25th', '415)244-6094', 'tomorrow', 'this June', 'Tuesday', 'the end of September', 'September 25', 'Thursday', '14 day', 'today', 'today', 'Halloween', 'today', 'tomorrow', 'tomorrow', 'this week', 'Tuesday', 'today', 'Monday', 'the day on Monday or', 'Tuesday', 'Saturday', 'Monday', 'Friday', 'tomorrow', 'Friday', 'this school year', 'This week', 'Wednesday', 'Wednesday', 'each day', '2001', 'up to 3 years', 'Thursday', 'today', 'Monday', 'Friday', 'this week', 'Tuesday', 'this Sunday', 'today', 'the beginning of the month', 'Saturday, March 25', 'this weekend', '713/853-5984', '713/853-6440', 'weekly', 'tomorrow', 'the past several months', 'Saturday', 'December 7', 'this week', 'Monday', 'Tuesday, January 8th', 'next week', 'Thursday', 'Friday', 'tomorrow', 'this weekend', 'Thursday, March 22', 'tomorrow', 'tomorrow', 'next week', 'tomorrow', 'this week', 'tomorrow', '1130', 'the weekend', 'today', 'Friday', 'daily', 'October 11th', 'this week', 'the 18th', 'Friday', 'Monday', 'November', 'this week', 'Tuesday', 'Tuesday', 'Wednesday', 'Monday', 'tomorrow', '2 day', 'Friday', 'Monday', 'last weekend', 'Monday', 'Jan 2000', 'yesterday', 'next week', 'that day', 'Tuesday, February 20, 2001', 'Tuesday', 'the weekend', '87-7449', 'today', 'Friday', '2001', 'tomorrow', 'July', 'Sunday', 'tomorrow', 'a year anniversary', 'the following week', 'today', 'early next week', 'March', 'March 28th', 'next week', 'tomorrow', 'tomorrow', 'tomorrow', 'Friday', 'next week', 'Monday, June 4th', 'all day', 'tomorrow', 'tomorrow', 'the end of the day', 'December 9', 'next Monday', 'tomorrow', 'the week', 'tomorrow', 'Thursday', 'today', 'this weekend', 'next week', 'next week', 'this weekend', 'the day and tomorrow', 'Thursday, November 29th', 'between now and Thursday', 'the week', 'next week', 'November 5th', 'today', 'this weekend', 'next week', 'this week', 'the next week', 'a couple days this week', 'next week', 'this week', 'tomorrow', 'a few weeks ago', 'Sunday', 'Monday', 'next week', 'Thursday', 'Wednesday', 'Thursday', 'this week', 'today', 'tomorrow', '3-0977', 'last Thursday', 'tomorrow', 'Thursday', 'Thursday', 'Friday', '3 nights', 'sunday', 'March', '21 years old', 'December', 'today', '251408768', 'Tuesday, August 27th, 2013', 'Friday', 'Friday', 'May 6 and May 24', 'November 11th and December 2nd, 2013', 'November 1, 2001', 'Monday, November 20th', 'a couple weeks', 'tomorrow', 'Monday, Jan. 22nd', 'Wednesday, Jan. 24th', 'today', 'the next few business days', 'the next couple of weeks', 'Sunday earlier', 'August 17', 'Thursday', 'next week', 'last week', 'XXXXXXXXX2159', 'Wednesday', 'April 12th', '2:30pm', 'March', 'Monday', '2001', 'Thursday', 'Friday', 'Monday', 'Tuesday', 'tomorrow', 'daily', 'tomorrow (Sunday', 'today', 'next week', 'every Friday', 'Wednesday', 'Tuesday', 'tomorrow', 'Friday', 'later this week', 'a few days', 'every week', 'this week', 'Sunday', 'Thursday', 'April 30', 'tomorrow', 'Friday', 'Monday', '2001', 'this next week', 'Saturday', 'Sunday', 'Tuesday', 'next week', 'next Monday', 'tomorrow', 'a later date', 'tomorrow', 'Friday', 'tomorrow', 'today', 'next week', 'last week', 'Monday', 'next Wednesday', 'Thursday', 'Saturday', '2000', 'Friday', 'two weeks', 'quarterly', 'Monday', 'late Oct.', 'today', 'tomorrow', 'tomorrow', 'Friday', 'the next few days', 'next week', 'annual', 'May 12, 2001', 'tomorrow', 'Monday', 'tomorrow', 'Monday', 'next week', 'Sunday', 'Thursday', 'Wednesday', 'Monday', 'Wednesday', 'Monday', 'today', 'Monday', 'next week', '10/31', 'Monday, December 18', 'Intra-month', 'next Monday', 'the end of the week', 'tomorrow', 'last week', 'Wednesday', 'next week', 'Wednesday, Dec. 13th', 'tomorrow', 'summer', 'April', 'May', 'summer', 'next week', 'Monday', 'Monday', 'tomorrow', 'Friday', 'Monday', '627-8172', 'next Tuesday/Wednesday', 'Thursday', 'between now and Monday', 'Friday', 'a day', 'Sunday', 'December', 'today', 'Monday', 'next week', '301/652-7877', 'tommorrow', 'today', 'tomorrow', 'Monday', 'Saturday', 'Friday', 'Friday', 'the next week', 'March 12', 'this week', 'last Sunday', 'Labor Day', 'the 17th', 'today', 'Christmas', 'tomorrow', 'season', 'season', 'today', 'tomorrow', 'Christmas', 'Friday, August 4th', '26301', 'this coming Monday', 'every other week', 'a week', 'tomorrow', 'monthly', 'last week', 'Thursday', '7-10', '1100', 'Monday', 'two days', 'Wednesday', 'Thursday', '2014', 'Tuesday, September 30th', 'January', 'these days', 'this week', 'Thursday', 'next week', 'early next week', 'Monday', '2000', 'this week', 'yesterday', 'the weekend', 'Monday', 'next week', 'the following week', 'next week', 'Tuesday', 'this week', 'the end of January', 'mid January', 'Wednesday', 'Thursday', 'early October', 'the next couple weeks', 'Friday', 'early next week', 'today', 'this weekend', 'this weekend', 'next summer', 'today', 'Week 2013', 'the next month', 'April 16', 'Monday', 'today', '15s', 'this week', 'today', 'next Monday', 'Thursday', 'all next week', 'next week', 'the next many months', 'September 5, 2000', 'tomorrow', 'weekly', 'Friday', 'weekly', 'this week', 'Dec. 17th', 'Thursday', 'this weekend', '2000', 'year', 'tomorrow', 'Thursday, November 28', 'Monday', 'Saturday', 'tomorrow', 'that day', 'this week', 'monthly', 'the 8:30 call tomorrow', 'next week', 'next year', 'this week', 'tomorrow', 'the next few weeks', 'Sunday', 'Saturday', 'April 11', 'same week', 'Saturday', 'Tuesday the 24th', 'Sunday', 'the next couple of days', 'Monday', 'next week', 'the weekend', 'this weekend', 'next Thursday', 'the last several weeks', 'Thursday', 'tomorrow', 'Sunday', 'tomorrow', 'the 25th - 28th', 'the 28th', 'tomorrow', 'Wednesday', '37323']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "BpSrJgY5TQrH",
        "outputId": "75e83a6a-eceb-4ed5-f1b2-19800856dce8"
      },
      "source": [
        "# result from second function\n",
        "print(date_extract_re(ask))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['100', '500', '1000', '10', '125', '148', '46', '2788', '186', '28', '01', '186', '28', '01', '20', '519', '323', '0214', '30', '30', '150', '130', '25', '52', '2000', '40', '40', '40', '00', 'July 31', '2014', '30 June 2012', '20', 'April 15', '14', '25', '365', '100', '12', '300', '365', '9/11', '2012', '45', '38', 'March 20', '2001', '02', '14', '21', '800', '493', '9489', '100', '10', '276', '243', '1628', '276', '690', '7548', '832', '301', '8746', '7/12', '25', '19', 'August 31', 'June 23', '2000', '18', '16', '02', '30', '31', '30-45', '99', '99', '3/16', '1999', '2000', '2081', '900', '01', '2013', '18', '10', '33.23', '120', '50.00', '1850', '1940', 'February 28', '2014', '20', '30', '75', '2000', '11', '56,000', '25', 'April 2011', '02', '12/18/11', '03', '12/18/11', '04', '12/18/11', '05', '06', '12/18/11', '18', '1 19', '2 20', '3 21', '4 22', '5 23', '6 24', 'April 5-19', '15,000', '055', 'June 27', '2001', 'Jan 26', '30', 'January 15', '01', '28', 'August 2013', 'August 22', '2012', 'August 23', '2012', '2012', '40', '2013', '2001', '150', '85', '145', '2.69', '21', '15.50', '20', '36', '50', '9136', '887', '6436', 'October 24', '30', '00', '95', '1890', '95', '1890', '781', '395', '2981', '781', '874', '0527', '781', '718', '8397', '781', '395', '2719', '7817', '1883', '97', 'July 31', '2013', '16', 'January 14', '2013', '20', '140', '01', '38', '27 Jun 14', '17', '2000', '11', '20', '20', '20', '600', '10', 'May 16', '30', '01', '27', '20', 'April 16', '2001', '24', 'Dec 22', 'April 23', '11', '00', 'January 29', '11', '00', '20', '15', 'June 14', '2001', '00', '15', '65', '2999', 'April 16', 'April 16', '17', '18', '19', 'August 4-10', '13', '14', '01', '22', '02 Sep 13', '40', '7707', '1-281', '366', '4507', '1-281', '366', '5090', '3756', '2014', '00', '10', '11', '272', '4.9951', '12', '00', '10', '00', '36', '29', '360', 'October 25', '7000', '1695', '76', '1000', '1000', '1000', '2.895', '15', '10,000', '16', '60-90', '10', '25,000', '30,000', '130', '200', '70', '30', '408', '390', '5291', '3051', '46', '12', '1-800', '548', '9554', 'January 16', '2013', 'January 18', '2013', '50', '3-5800', '1,000', '100', '200', '500', '17', '20', '22', '908', '1001', '100', '4.11', '20', '20', '90', '13', '12', '2013', '0123', 'June 2011', '13', '02/28/12', '14', '02/28/12', '15', '02/28/12', '16', '17', '02/28/12', '29', '1 30', '75', '20', '2013', '0123', 'July 11', '2029', '39', '3805', '71', '15', '15', '14', '5,000', '00', '2000', '40', 'March 2011', '12', '1 13', '2 14', '3 15', '4 16', '5 17', '6 18', '7 28', '12/17/11', '29', '12/17/11', '30', '12/17/11', '31', '0.99', 'December 31', '00', '101', '99', '1/2000', 'April 16', 'May 14', '20', '2001', '1-888', '926', '9988', '35', '3125', '130', '000', '5,000', '19', '03/28/2011', '99', '90', 'Feb 26', '2013', '11', '00', 'October 26', '2001', '2012', '1355', '63', '10', '30', 'May 25', '2000', '01', '018', '50', '01', '018', '50', '1-800', '769', '3571', '1910', 'January 29', '2001', '11', '15', '30', 'June 12', '2001', '30', '00', '20', '350', '36', '9007', '213', '613', '2836', '213', '613', '2950', '212', '704', '9900', '212', '704', '4312', '200', '15-19', '80.00', 'January 19', '2002', '00', '680', '68', '27', '2011', '10', '2014', '2014', '23', '4.44', '72.13', '30', '28 August 2011', '83', '15', '10', 'August 21', '2001', '30', '20', 'December 16', '2013', '30', '15', '15', '190', '000', '11', '150', '3346', '3346', '3349', '3349', '30', '30', '30', '20', 'August 28', '35-40', '10', 'August 18', '10', 'July 14', '29', '49', '10', '30', '2001', 'April 2010', '50', '30', '1989', '10,000', '1989', '10,000', 'October 17', '2013', '50', '30', '2514', '1561', '10', 'July 28', '2001', '10', '07', '06/26/14', '10', '39', '3548', '10', '52', '72', '77', '2001', '2001', '15', '25', '70', '10', '30', '01', '018', '6194', '7425', '18', '05/28/2011', '45', '10', '00', '10', '938', '310', '57', '49', '48', '45', '70,000', '2001', '500', '30', '7/12', 'January 25', '2001', '08', '36', '700', '11', 'September 19', '10/16', '2500', '16,000', '150', '20', '20', '01', '018', '2,500', '350', '000', '2014', '07-01 21', '35', '53', '330', '80', '20', '19.30', '13', '1201', '27', '130', '71.99', '10', '200', '000', '30', '6868', '0207', '15', '100', '80', '3518', '598', '9810', '9465', '9465', '3,500', '3600', '3600', '3600', '06-30-14', '1 Dec 2013', '30', '321', '29 April 2012', 'January 31', '2013', '50', '31', '7.00', '9.45', '30', '29', '713', '853', '6895', '01', '33', '26 Jun 14', '412', '279', '9298', '2012', '15', '978', '281', '0744', '11', '31', '3117', '167', '292', '0646', '0-3400', '713', '853', '3399', '713', '345', '4079', '713', '853', '0397', '24', '1-800', '30', 'June 20', '230', '2001', '20', '24', '713', '853', '6544', '20', '10-15', '35', '8.99', '10', '50', '2013', 'November 11', 'September 25', '415', '244', '6094', '713', '853', '5707', '3,000', '30', 'September 25', '14', '1.55', '5-10', '3689', '44', '28.00', '11', '00', '30', '11', '1-877', '428', '5608', '855', '962', '3621', '40,000', '25,000', '2001', '10', '100', 'March 25', '713', '853', '5984', '713', '853', '6440', '30', '00', '855', '962', '3621', '11', '30', '12', 'March 22', '707', '884', '4608', '30', '1130', '20', '00', 'Apr 98', '45', 'October 11', '18', '11', '00', '30', '6910', '1/26/00', 'Jan 2000', 'February 20', '2001', '30', '800', '87-7449', '2001', '11', '713', '783', '1223', 'March 30', 'March 28', 'November 29', '713', '334', '2887', '713', '302', '9570', '855', '331', '9531', '415', '782', '7822', '888', '486', '4722', '15', '30', '3-0977', '3.61', '00', '05/20', '05/20', '8.2.01', '15', '15', '50,000', '21', '20', '25', '2514', '0876', '11', '59', 'August 27', '2013', 'May 24', 'November 11', '2013', '45', '2001', '11', '00', '20', 'November 20', '22', '30', '24', '11', '15', '15', 'August 17', '104', '4532', '2159', 'April 12', '30', '30', 'Dec 2000', '30', '3689', '2001', '713', '853', '3848', '10', '877', '500', '3587', '00', '713', '222', '7667', '00', 'April 30', '2001', '33', '128', '888', '916', '7184', '0232', '25', '529', '01/12', '30', '00', '2000', '10', '00', '11', '00', '100', 'May 12', '2001', '11', '45', '45', '25', '360', '10/31', 'December 18', '30', '20', '13', '150', '09', '14', '22 Apr 14', '2001', '1850', '12', '24', '888', '486', '4722', '02', '01', '26 Jun 14', '09', '13', '21 Apr 14', '415', '505', '6633', '24', '855', '700', '5121', '505', '627', '8172', '10', '00', '203', '10', '10,000', '9,500', '10,000', '500', '30', '30', '30', '30', '301', '652', '7877', '7317', '713', '661', '6096', '10', 'March 12', '10', '10', '10', '00', '50,000', '06', 'January 2001', '17', '10', '713', '584', '2067', '800', '769', '3571', '30', '500', '2630', '11', '7-10', '1100', '10', '2014', 'September 30', '900', '2000', '4.14', '866', '333', '0989', '4864', '866', '757', '7752', '2013', 'April 16', '2.99', '15-25', '15', '7/24/00', '30', '00', '00', '10', '2000', '496', '17', '1,000', '100', '2000', 'November 28', '00', '30', '100', '908', '709', '7272', '415', '782', '7822', '630', '15', 'April 11', '30', '24', '30', '200', '2000', '30-40', '2012', '25', '28', '9910', '14', '28', '10', '111', '120', '3732']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mbi_spgqUDAW"
      },
      "source": [
        "#### d) Which one of the two approaches was better? Why do you think so? Would you use any of these approaches? Or a different one?\n",
        "- Spacy was better because spacy identifies dates based on pre-trained corpus where as regular expression is purely based on rule based logic. The uniformity is not maintained in regular expression. I would prefer spacy but that is based on the dataset's contents only. Overall, I would prefer to use an hybrid approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJkizfgwCXiV"
      },
      "source": [
        "### Question 5) (30 points) Train an LSTM model to classify the Cornell Movie Review data using the polarity_dataset V2.0. You can use the code for class 19, but take a note that you will have to adapt some of the parameters like: Review size = 450, epochs=5. You will use 85% of the dataset for training, and 15% for testing. Once you build the model, please display the sklearn classification report. What are you noticing here? Anything unexpected? How does this model compare to the one built with the IMDB dataset in class? Any ideas on how to improve it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-t-ukDnCcN1"
      },
      "source": [
        "# unzipping dataset\n",
        "!rm -rf __MACOSX/ txt_sentoken/ Shakespeare/ shakespeares-works_TXT_FolgerShakespeare/\n",
        "!unzip /content/drive/MyDrive/Projects/NLP/txt_sentoken.zip\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oATr6veoCerz"
      },
      "source": [
        "# creating set of documents i.e. list of all documents present in TRAINING folder\n",
        "folder_path = '/content/txt_sentoken/'\n",
        "file_content_corpus = []\n",
        "target_label = []\n",
        "# print(distance())\n",
        "sub_folders = []\n",
        "for i in os.walk(folder_path):\n",
        "  sub_folders.append(i[0])\n",
        "for folder in sub_folders:\n",
        "  files = os.walk(folder).__next__()[-1]   \n",
        "  for f in files:\n",
        "    if not f.startswith('.'):                                                      \n",
        "      file_content_corpus.append(open(os.path.join(folder, f),'r').read()) \n",
        "    # if os.path.join(folder,f) == '/content/exam1_dataset/TRAINING/negative/{}'.format(f)\n",
        "    if folder=='/content/txt_sentoken/pos':\n",
        "      target_label.append(1)\n",
        "    elif folder=='/content/txt_sentoken/neg':\n",
        "      target_label.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkv8Se-OCee2"
      },
      "source": [
        "np.random.seed(12345)\n",
        "X_train, X_test, y_train, y_test = train_test_split(file_content_corpus, target_label, test_size=0.15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdA4o8KVF-S4",
        "outputId": "3be43225-f5aa-4e77-9d0c-a3fb9e40f8b9"
      },
      "source": [
        "target_label[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UkToJr3CecQ"
      },
      "source": [
        "# Map for readable classnames\n",
        "class_names = [0,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEadQyNiCeZn"
      },
      "source": [
        "data = X_train + X_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SP-4aduECeS8",
        "outputId": "efa36fe6-72dd-4324-aa8f-b4c235eb6f37"
      },
      "source": [
        "# PREPROCESSING\n",
        "# lstm does not understand the words we need to encode it.\n",
        "word_index = {}\n",
        "# vocab_size = len(word_index)\n",
        "word_index[\"<PAD>\"] = 0\n",
        "word_index[\"<START>\"] = 1\n",
        "word_index[\"<UNKNOWN>\"] = 2\n",
        "word_index[\"<UNUSED>\"] = 3\n",
        "\n",
        "# encoding via tokenizing is providing very low accuracy.\n",
        "\"\"\"combine_data = ' '.join(data)\n",
        "tokenized_data = word_tokenize(combine_data)\n",
        "unique_tokens = set(tokenized_data)\"\"\"\n",
        "# encoding manually by looping through each sentence.\n",
        "\"\"\"start_count = 4 # because 4 keyvalues are set from 0-3\n",
        "data = ''.join(data)\n",
        "data = data.split(' ')\n",
        "data = list(set(data))\n",
        "for i in data:\n",
        "    if i not in word_index:\n",
        "        word_index[i] = start_count\n",
        "        start_count+=1\"\"\"\n",
        "\n",
        "# nested looping through tweets and words\n",
        "start_count = 4\n",
        "for i in data:\n",
        "  for j in i.split(' '):\n",
        "    if j not in word_index:\n",
        "      word_index[j] = start_count\n",
        "      start_count += 1\n",
        "\n",
        "\n",
        "# encoding technique-1# perform encoding by allocating random integers to each unique word\n",
        "\"\"\"from random import randint\n",
        "i = 4\n",
        "testing = [i += 1 word_index[word] = i for i in data for j in i.split(' ') if j not in word_index]\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"from random import randint\\ni = 4\\ntesting = [i += 1 word_index[word] = i for i in data for j in i.split(' ') if j not in word_index]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbYszCOXCeKT"
      },
      "source": [
        "# splitting the encoded values \n",
        "\n",
        "\"\"\"\n",
        "X_train_encode, X_test_encode = train_test_split(list(word_index.values),random_state=2361)\n",
        "\"\"\"\n",
        "X_train_encode=[]\n",
        "for tweet in X_train:\n",
        "    xtrain_list = []\n",
        "    for i in tweet.split(' '):\n",
        "      xtrain_list.append(word_index[i])\n",
        "        # try:\n",
        "  \n",
        "        # except:\n",
        "            # continue\n",
        "    X_train_encode.append(xtrain_list)\n",
        "X_test_encode=[]\n",
        "for ttweet in X_test:\n",
        "    xtest_list = []\n",
        "    for i in ttweet.split(' '):\n",
        "      xtest_list.append(word_index[i])\n",
        "        # try:\n",
        "            \n",
        "        # except:\n",
        "        #     continue\n",
        "    X_test_encode.append(xtest_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqMbZcAfCt0h",
        "outputId": "e4de4bcb-12ef-46b2-8aaf-7fd2045bcb49"
      },
      "source": [
        "#converting back the train_test split list variable to nDarray\n",
        "# X_train, X_test, y_train, y_test = np.ravel(X_train), np.ravel(X_test), np.ravel(y_train), np.ravel(y_test)\n",
        "X_train = np.array(X_train_encode)\n",
        "X_test = np.array(X_test_encode) \n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "review_length = 450\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen = review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen = review_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2IiIaOlC0mi",
        "outputId": "aed27651-7663-4cfa-8240-0c41bf53ea74"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = len(word_index), # The size of our vocabulary \n",
        "        output_dim = 32, # Dimensions to which each words shall be mapped\n",
        "        input_length = review_length # Length of input sequences\n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 \n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.LSTM(\n",
        "        units=32 \n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 \n",
        "    )\n",
        ")\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1, # Single unit\n",
        "        activation='sigmoid' # Sigmoid activation function (output from 0 to 1)\n",
        "    )\n",
        ")\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, # loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(), # optimiser function\n",
        "    metrics=['accuracy']) # reporting metric\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 450, 32)           1798496   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 450, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 1,806,849\n",
            "Trainable params: 1,806,849\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJtfRaqdC0Wh",
        "outputId": "e24a72e4-395b-4193-fdde-3d3ca5dacd05"
      },
      "source": [
        "y_tensor = tf.convert_to_tensor(X_train, dtype=tf.int32)\n",
        "y_tensor1 = tf.convert_to_tensor(y_train, dtype=tf.int32)\n",
        "history = model.fit(y_tensor, y_tensor1,batch_size=256,epochs=5,validation_split=0.2,verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "6/6 [==============================] - 34s 164ms/step - loss: 0.6932 - accuracy: 0.5089 - val_loss: 0.6930 - val_accuracy: 0.4941\n",
            "Epoch 2/5\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.6926 - accuracy: 0.5202 - val_loss: 0.6925 - val_accuracy: 0.5088\n",
            "Epoch 3/5\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.6910 - accuracy: 0.5478 - val_loss: 0.6920 - val_accuracy: 0.5118\n",
            "Epoch 4/5\n",
            "6/6 [==============================] - 0s 67ms/step - loss: 0.6890 - accuracy: 0.5347 - val_loss: 0.6912 - val_accuracy: 0.5118\n",
            "Epoch 5/5\n",
            "6/6 [==============================] - 0s 68ms/step - loss: 0.6851 - accuracy: 0.5495 - val_loss: 0.6894 - val_accuracy: 0.5294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32Z7jDauCuyX",
        "outputId": "e41e5b4b-d191-4a2b-bdbc-7946729d1d7f"
      },
      "source": [
        "predicted_classes = model.predict_classes(X_test)\n",
        "classification_report = classification_report(y_test, predicted_classes) # 0 - negative, 1 - positive\n",
        "print(classification_report)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.05      0.09       164\n",
            "           1       0.46      0.98      0.63       136\n",
            "\n",
            "    accuracy                           0.47       300\n",
            "   macro avg       0.59      0.51      0.36       300\n",
            "weighted avg       0.61      0.47      0.33       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CjWhPBQC_vu"
      },
      "source": [
        "#### What are you noticing here? Anything unexpected? \n",
        " - The accuracy is nearly 50% on average. This is unexpected.\n",
        "\n",
        "#### How does this model compare to the one built with the IMDB dataset in class?\n",
        "In both the cases the accuracy increases with every epoch but in Cornless Dataset it is only marginal increase. Comparing IMDB and Cornell's classification report. The weighted average values are more uniform in IMDB dataset.\n",
        "\n",
        "#### Any ideas on how to improve it?\n",
        "- Increase the dataset size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2HAMjYeWIXu"
      },
      "source": [
        "#### Question 6) (30 points) Use the train.txt file from the PubMed 20K RCT dataset(https://github.com/Franck-Dernoncourt/pubmed-rct/tree/master/PubMed_20k_RCT) fine-tune a BERT transformer (class 9 code). This task is a bit different as the one seen in class, here the source dataset has FIVE different classes: background, objective, method, result, and conclusion. Once the BERT model is fine-tuned, classify the: test.txt set. Please present the per-class classification report (accuracy, precision, recall, f1-score metrics). Also, present the global metrics - all classes (accuracy, precision, recall, f1-score metrics). Did you model beat the baseline results (https://arxiv.org/pdf/1710.06071.pdf)? What do you think you can do to improve it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WSVPi4uXR95"
      },
      "source": [
        "# !wget \"https://raw.githubusercontent.com/Franck-Dernoncourt/pubmed-rct/master/PubMed_20k_RCT/train.txt\" -O q6_train.txt\n",
        "# !wget \"https://github.com/Franck-Dernoncourt/pubmed-rct/blob/master/PubMed_20k_RCT/test.txt\" -O q6_test.txt\n",
        "!wget \"https://raw.githubusercontent.com/Franck-Dernoncourt/pubmed-rct/master/PubMed_20k_RCT/train.txt?raw=true\" -O q6_train.txt\n",
        "!wget \"https://raw.githubusercontent.com/Franck-Dernoncourt/pubmed-rct/master/PubMed_20k_RCT/train.txt?raw=true\" -O q6_test.txt\n",
        "clear_output()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Htt3oUvjZ8G8",
        "outputId": "0d1b8201-f7f6-4b96-f03b-903b0bba01d1"
      },
      "source": [
        "!head q6_train.txt"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###24293578\n",
            "OBJECTIVE\tTo investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n",
            "METHODS\tA total of 125 patients with primary knee OA were randomized 1:1 ; 63 received 7.5 mg/day of prednisolone and 62 received placebo for 6 weeks .\n",
            "METHODS\tOutcome measures included pain reduction and improvement in function scores and systemic inflammation markers .\n",
            "METHODS\tPain was assessed using the visual analog pain scale ( 0-100 mm ) .\n",
            "METHODS\tSecondary outcome measures included the Western Ontario and McMaster Universities Osteoarthritis Index scores , patient global assessment ( PGA ) of the severity of knee OA , and 6-min walk distance ( 6MWD ) .\n",
            "METHODS\tSerum levels of interleukin 1 ( IL-1 ) , IL-6 , tumor necrosis factor ( TNF ) - , and high-sensitivity C-reactive protein ( hsCRP ) were measured .\n",
            "RESULTS\tThere was a clinically relevant reduction in the intervention group compared to the placebo group for knee pain , physical function , PGA , and 6MWD at 6 weeks .\n",
            "RESULTS\tThe mean difference between treatment arms ( 95 % CI ) was 10.9 ( 4.8-18 .0 ) , p < 0.001 ; 9.5 ( 3.7-15 .4 ) , p < 0.05 ; 15.7 ( 5.3-26 .1 ) , p < 0.001 ; and 86.9 ( 29.8-144 .1 ) , p < 0.05 , respectively .\n",
            "RESULTS\tFurther , there was a clinically relevant reduction in the serum levels of IL-1 , IL-6 , TNF - , and hsCRP at 6 weeks in the intervention group when compared to the placebo group .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1UnmKLwiRyX"
      },
      "source": [
        "with open('q6_train.txt', 'r') as f:\n",
        "    train_data = f.read()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzdmcUJFlyXU"
      },
      "source": [
        "lines = train_data.split('\\n')\n",
        "five_labels = ['OBJECTIVE','METHODS','RESULTS','CONCLUSIONS','BACKGROUND']"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8YJSqN8slyl"
      },
      "source": [
        "# llen = int(0.9*len(lines))\n",
        "# llen"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kBXlLBymdlv"
      },
      "source": [
        "X= []\n",
        "y = []"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KILcvsNKl4_x"
      },
      "source": [
        "for line in lines:\n",
        "  if(len(line.split('\\t')) == 2):\n",
        "    label, pct = line.split('\\t')\n",
        "    if (label in five_labels):\n",
        "      X.append(pct)\n",
        "      y.append(five_labels.index(label))"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4XhhrCfkUdq"
      },
      "source": [
        "sentences = X\n",
        "labels = y"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EHzq6w2Lnu3T",
        "outputId": "dcc22e83-b34e-4dd1-9c76-34bcdc2caa2b"
      },
      "source": [
        "import os\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_Uym3U4GnwNy",
        "outputId": "a385b01f-7062-4169-8c7b-5e4141442278"
      },
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  To investigate the efficacy of 6 weeks of daily low-dose oral prednisolone in improving pain , mobility , and systemic low-grade inflammation in the short term and whether the effect would be sustained at 12 weeks in older adults with moderate to severe knee osteoarthritis ( OA ) .\n",
            "Token IDs: tensor([  101,  2000,  8556,  1996, 21150,  1997,  1020,  3134,  1997,  3679,\n",
            "         2659,  1011, 13004,  8700,  3653,  2094,  8977, 12898,  2638,  1999,\n",
            "         9229,  3255,  1010, 12969,  1010,  1998, 22575,  2659,  1011,  3694,\n",
            "        21733,  1999,  1996,  2460,  2744,  1998,  3251,  1996,  3466,  2052,\n",
            "         2022,  8760,  2012,  2260,  3134,  1999,  3080,  6001,  2007,  8777,\n",
            "         2000,  5729,  6181,  9808,  2618, 10441, 15265, 14778,  2483,  1006,\n",
            "         1051,  2050,  1007,   102])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "__0EizMLo9Dt",
        "outputId": "9a135b50-96c8-48ca-dc99-c31d7c2dc7d7"
      },
      "source": [
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "162,036 training samples\n",
            "18,004 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmw39vZbpUpP"
      },
      "source": [
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLtGZRw2bvS2"
      },
      "source": [
        "#### Loading and Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fr9CM9JkbxYp",
        "outputId": "ace2011a-bfcb-426b-8066-c19c92034ee7"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 5, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJSmNPxbb6Ze"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkqNq5swcESv"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TY12aNv3cHPg"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxxWogvgcPF1"
      },
      "source": [
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UZRGNaE3cW9i",
        "outputId": "c862e89c-551d-4e93-bca9-b1ead9888361"
      },
      "source": [
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:13.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:27.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:40.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:00:54.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:08.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:22.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:36.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:01:50.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:04.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:18.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:33.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:02:47.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:01.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:15.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:30.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:03:44.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:03:58.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:13.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:27.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:04:41.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:04:55.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:10.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:24.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:05:38.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:05:53.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:07.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:06:21.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:06:35.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:06:50.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:04.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:07:18.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:07:33.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:07:47.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:01.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:08:15.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:08:30.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:08:44.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:08:58.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:09:13.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:09:27.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:09:41.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:09:56.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:10:10.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:10:24.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:10:38.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:10:53.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:11:07.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:11:21.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:11:36.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:11:50.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:12:04.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:12:19.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:12:33.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:12:47.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:13:01.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:13:16.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:13:30.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:13:44.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:13:59.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:14:13.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:14:27.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:14:41.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:14:56.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:15:10.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:15:24.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:15:39.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:15:53.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:16:07.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:16:22.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:16:36.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:16:50.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:17:04.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:17:19.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:17:33.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:17:47.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:18:02.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:18:16.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:18:30.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:18:44.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:18:59.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:19:13.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:19:27.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:19:42.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:19:56.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:20:10.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:20:24.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:20:39.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:20:53.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:21:07.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:21:22.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:21:36.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:21:50.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:22:04.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:22:19.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:22:33.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:22:47.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:23:02.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:23:16.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:23:30.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:23:45.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:23:59.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:24:13.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:24:27.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:24:42.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:24:56.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:25:10.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:25:25.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:25:39.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:25:53.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:26:07.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:26:22.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:26:36.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:26:50.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:27:04.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:27:19.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:27:33.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:27:47.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:28:02.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:28:16.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:28:30.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:28:45.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:28:59.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:29:13.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:29:27.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:29:42.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:29:56.\n",
            "\n",
            "  Average training loss: 0.41\n",
            "  Training epcoh took: 0:30:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.37\n",
            "  Validation took: 0:01:06\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:14.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:29.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:43.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:00:57.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:11.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:26.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:40.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:01:54.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:23.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:37.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:02:52.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:06.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:20.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:34.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:03:49.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:03.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:17.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:32.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:04:46.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:00.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:15.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:29.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:05:43.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:05:57.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:12.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:06:26.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:06:40.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:06:55.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:09.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:07:23.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:07:37.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:07:52.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:06.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:08:20.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:08:35.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:08:49.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:03.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:09:18.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:09:32.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:09:46.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:00.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:10:15.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:10:29.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:10:43.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:10:58.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:11:12.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:11:26.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:11:40.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:11:55.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:12:09.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:12:23.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:12:38.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:12:52.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:13:06.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:13:21.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:13:35.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:13:49.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:14:03.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:14:18.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:14:32.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:14:46.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:15:01.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:15:15.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:15:29.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:15:44.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:15:58.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:16:12.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:16:26.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:16:41.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:16:55.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:17:09.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:17:24.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:17:38.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:17:52.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:18:07.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:18:21.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:18:35.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:18:50.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:19:04.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:19:18.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:19:32.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:19:47.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:20:01.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:20:15.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:20:30.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:20:44.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:20:58.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:21:13.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:21:27.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:21:41.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:21:56.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:22:10.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:22:24.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:22:38.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:22:53.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:23:07.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:23:21.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:23:35.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:23:50.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:24:04.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:24:18.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:24:33.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:24:47.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:25:01.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:25:16.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:25:30.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:25:44.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:25:58.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:26:13.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:26:27.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:26:41.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:26:56.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:27:10.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:27:24.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:27:39.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:27:53.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:28:07.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:28:21.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:28:36.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:28:50.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:29:04.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:29:19.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:29:33.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:29:47.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:30:02.\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:30:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.36\n",
            "  Validation took: 0:01:06\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:14.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:29.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:43.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:00:57.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:12.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:26.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:40.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:01:55.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:23.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:37.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:02:52.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:06.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:20.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:35.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:03:49.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:03.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:17.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:32.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:04:46.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:00.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:15.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:29.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:05:43.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:05:58.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:12.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:06:26.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:06:40.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:06:55.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:09.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:07:23.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:07:38.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:07:52.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:06.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:08:21.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:08:35.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:08:49.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:04.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:09:18.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:09:32.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:09:46.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:01.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:10:15.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:10:29.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:10:44.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:10:58.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:11:12.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:11:27.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:11:41.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:11:55.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:12:09.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:12:24.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:12:38.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:12:52.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:13:07.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:13:21.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:13:35.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:13:50.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:14:04.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:14:18.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:14:33.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:14:47.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:15:01.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:15:15.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:15:30.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:15:44.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:15:58.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:16:13.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:16:27.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:16:41.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:16:56.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:17:10.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:17:24.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:17:38.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:17:53.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:18:07.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:18:21.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:18:36.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:18:50.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:19:04.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:19:19.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:19:33.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:19:47.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:20:01.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:20:16.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:20:30.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:20:44.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:20:59.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:21:13.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:21:27.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:21:41.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:21:56.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:22:10.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:22:24.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:22:39.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:22:53.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:23:07.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:23:22.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:23:36.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:23:50.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:24:04.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:24:19.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:24:33.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:24:47.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:25:02.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:25:16.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:25:30.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:25:44.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:25:59.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:26:13.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:26:27.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:26:42.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:26:56.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:27:10.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:27:25.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:27:39.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:27:53.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:28:07.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:28:22.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:28:36.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:28:50.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:29:05.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:29:19.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:29:33.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:29:48.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:30:02.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epcoh took: 0:30:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.39\n",
            "  Validation took: 0:01:06\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  5,064.    Elapsed: 0:00:14.\n",
            "  Batch    80  of  5,064.    Elapsed: 0:00:29.\n",
            "  Batch   120  of  5,064.    Elapsed: 0:00:43.\n",
            "  Batch   160  of  5,064.    Elapsed: 0:00:57.\n",
            "  Batch   200  of  5,064.    Elapsed: 0:01:12.\n",
            "  Batch   240  of  5,064.    Elapsed: 0:01:26.\n",
            "  Batch   280  of  5,064.    Elapsed: 0:01:40.\n",
            "  Batch   320  of  5,064.    Elapsed: 0:01:54.\n",
            "  Batch   360  of  5,064.    Elapsed: 0:02:09.\n",
            "  Batch   400  of  5,064.    Elapsed: 0:02:23.\n",
            "  Batch   440  of  5,064.    Elapsed: 0:02:37.\n",
            "  Batch   480  of  5,064.    Elapsed: 0:02:52.\n",
            "  Batch   520  of  5,064.    Elapsed: 0:03:06.\n",
            "  Batch   560  of  5,064.    Elapsed: 0:03:20.\n",
            "  Batch   600  of  5,064.    Elapsed: 0:03:35.\n",
            "  Batch   640  of  5,064.    Elapsed: 0:03:49.\n",
            "  Batch   680  of  5,064.    Elapsed: 0:04:03.\n",
            "  Batch   720  of  5,064.    Elapsed: 0:04:18.\n",
            "  Batch   760  of  5,064.    Elapsed: 0:04:32.\n",
            "  Batch   800  of  5,064.    Elapsed: 0:04:46.\n",
            "  Batch   840  of  5,064.    Elapsed: 0:05:00.\n",
            "  Batch   880  of  5,064.    Elapsed: 0:05:15.\n",
            "  Batch   920  of  5,064.    Elapsed: 0:05:29.\n",
            "  Batch   960  of  5,064.    Elapsed: 0:05:43.\n",
            "  Batch 1,000  of  5,064.    Elapsed: 0:05:58.\n",
            "  Batch 1,040  of  5,064.    Elapsed: 0:06:12.\n",
            "  Batch 1,080  of  5,064.    Elapsed: 0:06:26.\n",
            "  Batch 1,120  of  5,064.    Elapsed: 0:06:41.\n",
            "  Batch 1,160  of  5,064.    Elapsed: 0:06:55.\n",
            "  Batch 1,200  of  5,064.    Elapsed: 0:07:09.\n",
            "  Batch 1,240  of  5,064.    Elapsed: 0:07:24.\n",
            "  Batch 1,280  of  5,064.    Elapsed: 0:07:38.\n",
            "  Batch 1,320  of  5,064.    Elapsed: 0:07:52.\n",
            "  Batch 1,360  of  5,064.    Elapsed: 0:08:06.\n",
            "  Batch 1,400  of  5,064.    Elapsed: 0:08:21.\n",
            "  Batch 1,440  of  5,064.    Elapsed: 0:08:35.\n",
            "  Batch 1,480  of  5,064.    Elapsed: 0:08:49.\n",
            "  Batch 1,520  of  5,064.    Elapsed: 0:09:04.\n",
            "  Batch 1,560  of  5,064.    Elapsed: 0:09:18.\n",
            "  Batch 1,600  of  5,064.    Elapsed: 0:09:32.\n",
            "  Batch 1,640  of  5,064.    Elapsed: 0:09:46.\n",
            "  Batch 1,680  of  5,064.    Elapsed: 0:10:01.\n",
            "  Batch 1,720  of  5,064.    Elapsed: 0:10:15.\n",
            "  Batch 1,760  of  5,064.    Elapsed: 0:10:29.\n",
            "  Batch 1,800  of  5,064.    Elapsed: 0:10:44.\n",
            "  Batch 1,840  of  5,064.    Elapsed: 0:10:58.\n",
            "  Batch 1,880  of  5,064.    Elapsed: 0:11:12.\n",
            "  Batch 1,920  of  5,064.    Elapsed: 0:11:27.\n",
            "  Batch 1,960  of  5,064.    Elapsed: 0:11:41.\n",
            "  Batch 2,000  of  5,064.    Elapsed: 0:11:55.\n",
            "  Batch 2,040  of  5,064.    Elapsed: 0:12:10.\n",
            "  Batch 2,080  of  5,064.    Elapsed: 0:12:24.\n",
            "  Batch 2,120  of  5,064.    Elapsed: 0:12:38.\n",
            "  Batch 2,160  of  5,064.    Elapsed: 0:12:52.\n",
            "  Batch 2,200  of  5,064.    Elapsed: 0:13:07.\n",
            "  Batch 2,240  of  5,064.    Elapsed: 0:13:21.\n",
            "  Batch 2,280  of  5,064.    Elapsed: 0:13:35.\n",
            "  Batch 2,320  of  5,064.    Elapsed: 0:13:50.\n",
            "  Batch 2,360  of  5,064.    Elapsed: 0:14:04.\n",
            "  Batch 2,400  of  5,064.    Elapsed: 0:14:18.\n",
            "  Batch 2,440  of  5,064.    Elapsed: 0:14:33.\n",
            "  Batch 2,480  of  5,064.    Elapsed: 0:14:47.\n",
            "  Batch 2,520  of  5,064.    Elapsed: 0:15:01.\n",
            "  Batch 2,560  of  5,064.    Elapsed: 0:15:15.\n",
            "  Batch 2,600  of  5,064.    Elapsed: 0:15:30.\n",
            "  Batch 2,640  of  5,064.    Elapsed: 0:15:44.\n",
            "  Batch 2,680  of  5,064.    Elapsed: 0:15:58.\n",
            "  Batch 2,720  of  5,064.    Elapsed: 0:16:13.\n",
            "  Batch 2,760  of  5,064.    Elapsed: 0:16:27.\n",
            "  Batch 2,800  of  5,064.    Elapsed: 0:16:41.\n",
            "  Batch 2,840  of  5,064.    Elapsed: 0:16:55.\n",
            "  Batch 2,880  of  5,064.    Elapsed: 0:17:10.\n",
            "  Batch 2,920  of  5,064.    Elapsed: 0:17:24.\n",
            "  Batch 2,960  of  5,064.    Elapsed: 0:17:38.\n",
            "  Batch 3,000  of  5,064.    Elapsed: 0:17:53.\n",
            "  Batch 3,040  of  5,064.    Elapsed: 0:18:07.\n",
            "  Batch 3,080  of  5,064.    Elapsed: 0:18:21.\n",
            "  Batch 3,120  of  5,064.    Elapsed: 0:18:36.\n",
            "  Batch 3,160  of  5,064.    Elapsed: 0:18:50.\n",
            "  Batch 3,200  of  5,064.    Elapsed: 0:19:04.\n",
            "  Batch 3,240  of  5,064.    Elapsed: 0:19:18.\n",
            "  Batch 3,280  of  5,064.    Elapsed: 0:19:33.\n",
            "  Batch 3,320  of  5,064.    Elapsed: 0:19:47.\n",
            "  Batch 3,360  of  5,064.    Elapsed: 0:20:01.\n",
            "  Batch 3,400  of  5,064.    Elapsed: 0:20:16.\n",
            "  Batch 3,440  of  5,064.    Elapsed: 0:20:30.\n",
            "  Batch 3,480  of  5,064.    Elapsed: 0:20:44.\n",
            "  Batch 3,520  of  5,064.    Elapsed: 0:20:59.\n",
            "  Batch 3,560  of  5,064.    Elapsed: 0:21:13.\n",
            "  Batch 3,600  of  5,064.    Elapsed: 0:21:27.\n",
            "  Batch 3,640  of  5,064.    Elapsed: 0:21:41.\n",
            "  Batch 3,680  of  5,064.    Elapsed: 0:21:56.\n",
            "  Batch 3,720  of  5,064.    Elapsed: 0:22:10.\n",
            "  Batch 3,760  of  5,064.    Elapsed: 0:22:24.\n",
            "  Batch 3,800  of  5,064.    Elapsed: 0:22:39.\n",
            "  Batch 3,840  of  5,064.    Elapsed: 0:22:53.\n",
            "  Batch 3,880  of  5,064.    Elapsed: 0:23:07.\n",
            "  Batch 3,920  of  5,064.    Elapsed: 0:23:22.\n",
            "  Batch 3,960  of  5,064.    Elapsed: 0:23:36.\n",
            "  Batch 4,000  of  5,064.    Elapsed: 0:23:50.\n",
            "  Batch 4,040  of  5,064.    Elapsed: 0:24:04.\n",
            "  Batch 4,080  of  5,064.    Elapsed: 0:24:19.\n",
            "  Batch 4,120  of  5,064.    Elapsed: 0:24:33.\n",
            "  Batch 4,160  of  5,064.    Elapsed: 0:24:47.\n",
            "  Batch 4,200  of  5,064.    Elapsed: 0:25:02.\n",
            "  Batch 4,240  of  5,064.    Elapsed: 0:25:16.\n",
            "  Batch 4,280  of  5,064.    Elapsed: 0:25:30.\n",
            "  Batch 4,320  of  5,064.    Elapsed: 0:25:44.\n",
            "  Batch 4,360  of  5,064.    Elapsed: 0:25:59.\n",
            "  Batch 4,400  of  5,064.    Elapsed: 0:26:13.\n",
            "  Batch 4,440  of  5,064.    Elapsed: 0:26:27.\n",
            "  Batch 4,480  of  5,064.    Elapsed: 0:26:42.\n",
            "  Batch 4,520  of  5,064.    Elapsed: 0:26:56.\n",
            "  Batch 4,560  of  5,064.    Elapsed: 0:27:10.\n",
            "  Batch 4,600  of  5,064.    Elapsed: 0:27:25.\n",
            "  Batch 4,640  of  5,064.    Elapsed: 0:27:39.\n",
            "  Batch 4,680  of  5,064.    Elapsed: 0:27:53.\n",
            "  Batch 4,720  of  5,064.    Elapsed: 0:28:07.\n",
            "  Batch 4,760  of  5,064.    Elapsed: 0:28:22.\n",
            "  Batch 4,800  of  5,064.    Elapsed: 0:28:36.\n",
            "  Batch 4,840  of  5,064.    Elapsed: 0:28:50.\n",
            "  Batch 4,880  of  5,064.    Elapsed: 0:29:05.\n",
            "  Batch 4,920  of  5,064.    Elapsed: 0:29:19.\n",
            "  Batch 4,960  of  5,064.    Elapsed: 0:29:33.\n",
            "  Batch 5,000  of  5,064.    Elapsed: 0:29:48.\n",
            "  Batch 5,040  of  5,064.    Elapsed: 0:30:02.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:30:10\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.87\n",
            "  Validation Loss: 0.43\n",
            "  Validation took: 0:01:06\n",
            "\n",
            "Training complete!\n",
            "Total training took 2:05:01 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VWoGGVFce0X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "bbe81b8c-5abe-4f57-89aa-07080b6101fb"
      },
      "source": [
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.41</td>\n",
              "      <td>0.37</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:30:05</td>\n",
              "      <td>0:01:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.36</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:30:10</td>\n",
              "      <td>0:01:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0.39</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:30:10</td>\n",
              "      <td>0:01:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0:30:10</td>\n",
              "      <td>0:01:06</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.41         0.37           0.87       0:30:05         0:01:06\n",
              "2               0.31         0.36           0.87       0:30:10         0:01:06\n",
              "3               0.25         0.39           0.87       0:30:10         0:01:06\n",
              "4               0.20         0.43           0.87       0:30:10         0:01:06"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vVyp6q-cNidJ",
        "outputId": "731f9e69-7bd5-4adb-e183-21bd7795def4"
      },
      "source": [
        "with open('q6_test.txt', 'r') as f:\n",
        "    train_data = f.read()\n",
        "lines = train_data.split('\\n')\n",
        "five_labels = ['OBJECTIVE','METHODS','RESULTS','CONCLUSIONS','BACKGROUND']\n",
        "X= []\n",
        "y = []\n",
        "for line in lines:\n",
        "  if(len(line.split('\\t')) == 2):\n",
        "    label, pct = line.split('\\t')\n",
        "    if (label in five_labels):\n",
        "      X.append(pct)\n",
        "      y.append(five_labels.index(label))\n",
        "sentences = X\n",
        "labels = y\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jSBRsAMbMQG"
      },
      "source": [
        "#### Evaluation on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4d0d02zbOFm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c99268a1-2464-41d1-da39-0db1c5cc407f"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 180,040 test sentences...\n",
            "    DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "p1rrF7OFeCYw",
        "outputId": "8a10119b-6f34-492d-d63c-74296c102ce2"
      },
      "source": [
        "len(predictions), len(true_labels)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5627, 5627)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "39m5OArlZtqN",
        "outputId": "3e0fedc5-c6f5-4221-b6eb-498e8250465c"
      },
      "source": [
        "\n",
        "f1 = f1_score(labels.flatten(), np.argmax(predictions, axis=0).flatten(), average='weighted')\n",
        "acc= accuracy_score(labels.flatten(), np.argmax(predictions, axis=1).flatten())\n",
        "precision = precision_score(labels.flatten(),np.argmax(predictions, axis=1).flatten())\n",
        "recall = recall_score(labels.flatten(),np.argmax(predictions, axis=1).flatten())\n",
        "#class level accuracy\n",
        "predictions_flat = np.argmax(predictions, axis=1).flatten()\n",
        "labels_flat = labels.flatten()\n",
        "for label in np.unique(labels_flat):\n",
        "    y_predictions = predictions_flat[labels_flat==label]\n",
        "    y_true = labels_flat[labels_flat==label]\n",
        "    print(f'Class: {label_dict[label]}')\n",
        "    print(f'Accuracy: {len(y_predictions[y_predictions==label])}/{len(y_true)}\\n')"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-9dad736ab941>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Class: {label_dict[label]}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mval_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0maccuracy_per_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-82-9dad736ab941>\u001b[0m in \u001b[0;36mf1_score_func\u001b[0;34m(preds, labels)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Performance metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mf1_score_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpreds_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlabels_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \"\"\"\n\u001b[0;32m-> 1188\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zKzYwBK2K_yQ",
        "outputId": "7149bfdd-2d76-4eea-c2da-5251263fc4ab"
      },
      "source": [
        "predictions[0]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 5.8232145 , -2.0920217 , -3.7299933 , -2.654709  ,  1.5410722 ],\n",
              "       [-1.525281  ,  6.388547  ,  0.34785506, -3.814616  , -1.5841421 ],\n",
              "       [-0.816647  ,  4.9769335 ,  0.5543224 , -3.7431638 , -1.3238596 ],\n",
              "       [-1.2828058 ,  6.247549  , -0.15586866, -3.6116688 , -1.6498828 ],\n",
              "       [-0.75484574,  5.626166  , -0.00945846, -4.241919  , -1.1067168 ],\n",
              "       [-1.2156655 ,  5.726096  ,  1.123415  , -3.9201555 , -1.7457263 ],\n",
              "       [-3.3304958 , -1.2500113 ,  6.498452  ,  1.7350141 , -2.7433114 ],\n",
              "       [-3.0627828 ,  0.41246885,  6.1693068 , -0.9531187 , -2.2974741 ],\n",
              "       [-3.0556512 , -2.0077312 ,  5.989752  ,  2.6481817 , -2.5036788 ],\n",
              "       [-2.8040762 ,  0.10028925,  6.006577  , -0.6203381 , -2.4171815 ],\n",
              "       [-3.043339  ,  1.8088124 ,  5.658327  , -1.9199462 , -2.2659333 ],\n",
              "       [-1.1644218 , -2.0514505 , -1.827896  ,  6.2746367 , -0.41282725],\n",
              "       [ 3.959795  , -2.4701176 , -3.6191666 , -1.8796208 ,  4.05325   ],\n",
              "       [ 3.610219  , -2.794104  , -3.6055446 , -1.7027738 ,  4.5662174 ],\n",
              "       [ 4.9222484 , -1.5334456 , -3.901255  , -3.2275271 ,  2.8726466 ],\n",
              "       [ 4.0627656 , -0.82830024, -3.4694383 , -3.419018  ,  2.896263  ],\n",
              "       [-0.8081873 ,  4.6654825 ,  1.8358253 , -3.810094  , -2.047723  ],\n",
              "       [-0.8763029 ,  5.404532  ,  0.91144294, -3.7991223 , -1.9974719 ],\n",
              "       [-0.4416295 ,  5.7908416 , -0.75624704, -4.2720976 , -0.9119308 ],\n",
              "       [-2.7720942 ,  0.4227989 ,  6.3263426 , -0.8568377 , -2.9398162 ],\n",
              "       [-2.6473758 , -1.4498016 ,  5.861198  ,  1.4474463 , -2.451373  ],\n",
              "       [-1.3618747 , -2.45782   , -0.43327367,  6.8968267 , -1.3374497 ],\n",
              "       [-1.6097337 , -3.0196598 ,  0.502099  ,  6.5507917 , -1.1428164 ],\n",
              "       [ 3.296501  , -3.07549   , -3.416952  , -1.1244353 ,  4.737388  ],\n",
              "       [ 4.0572724 , -1.4429979 , -3.8650298 , -2.547777  ,  3.5898395 ],\n",
              "       [-1.4292834 ,  6.4837193 , -0.8994882 , -3.2582672 , -1.2726862 ],\n",
              "       [-0.4444453 ,  5.4335284 , -0.39536017, -4.158445  , -1.1626755 ],\n",
              "       [-1.2995542 ,  6.602998  , -1.4566722 , -2.872668  , -1.3855699 ],\n",
              "       [-1.2860074 ,  6.330889  ,  0.39130053, -3.7853024 , -2.007073  ],\n",
              "       [-0.9068142 ,  6.149389  , -0.50787026, -3.6438777 , -1.756531  ],\n",
              "       [-0.7185677 ,  5.6431828 , -0.05233878, -3.7925565 , -1.7324742 ],\n",
              "       [-2.7915142 , -0.26574263,  6.692334  , -0.89536166, -2.4188328 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3NPFaw1dXuoW",
        "outputId": "1eb32ead-7663-47c9-d81c-bea26d6f22e8"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "# Evaluate each test batch using Matthew's correlation coefficient\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "# For each input batch...\n",
        "for i in range(len(true_labels)):\n",
        "  \n",
        "  # The predictions for this batch are a 2-column ndarray (one column for \"0\" \n",
        "  # and one column for \"1\"). Pick the label with the highest value and turn this\n",
        "  # in to a list of 0s and 1s.\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  # Calculate and store the coef for this batch.  \n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)\n",
        "# Combine the results across all batches. \n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "# For each sample, pick the label (0 or 1) with the higher score.\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "Total MCC: 0.919\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sv4logJUajje"
      },
      "source": [
        "# #  performance metrics \n",
        "# ma_cv_acc = accuracy_score(may_test,mac_predict)\n",
        "# ma_cv_pre = precision_score(may_test,mac_predict)\n",
        "# ma_cv_re = recall_score(may_test,mac_predict)\n",
        "# ma_cv_f1 = f1_score(mac_predict, may_test, average='macro')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pQdNpoPiWze2",
        "outputId": "e1a83e46-646c-49e8-ad3b-ec6d49dc04a9"
      },
      "source": [
        "import os\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "\n",
        "output_dir = './model_save/'\n",
        "\n",
        "# Create output directory if needed\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "print(\"Saving model to %s\" % output_dir)\n",
        "\n",
        "# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "# They can then be reloaded using `from_pretrained()\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to ./model_save/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('./model_save/tokenizer_config.json',\n",
              " './model_save/special_tokens_map.json',\n",
              " './model_save/vocab.txt',\n",
              " './model_save/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-ancdKb6XBSg",
        "outputId": "412c9e44-c4e0-4bd6-e6e2-ea0901094852"
      },
      "source": [
        "# Mount Google Drive to this Notebook instance.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CgrrkkoXQRb"
      },
      "source": [
        "# Copy the model files to a directory in your Google Drive.\n",
        "!cp -r ./model_save/ \"./drive/MyDrive/models/\" "
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XW51Q5inXpkC"
      },
      "source": [
        "# # Load a trained model and vocabulary that you have fine-tuned\n",
        "# model = model_class.from_pretrained(output_dir)\n",
        "# tokenizer = tokenizer_class.from_pretrained(output_dir)\n",
        "\n",
        "# # Copy the model to the GPU.\n",
        "# model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6Rf9Bi0Y2Kk"
      },
      "source": [
        "#### Did you model beat the baseline results (https://arxiv.org/pdf/1710.06071.pdf)? \n",
        "\n",
        "#### What do you think you can do to improve it"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOsSpSJBw7b_"
      },
      "source": [
        "#### Bonus Question: (50 points) Solve question 6 but instead for fine-tuning BERT, use: BioBert (20 points) and BlueBERT (20 points) and compare the results of the three approaches in a nice table. Answer the following questions: Did you model beat the baseline results (https://arxiv.org/pdf/1710.06071.pdf)? What do you think you can do to improve it?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bPNHnzkw-R_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtpKEEnOoX9G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUP1UOAVoX_l"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtA_MGvdoYA6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}