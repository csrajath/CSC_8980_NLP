{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rcs1_TNLP_CSC_8980_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1a1MwRe-7gPTcOGw2MLnjCVjla1Kqlk2j",
      "authorship_tag": "ABX9TyPtkImBZiqPXn6lt4hhLRCD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csrajath/CSC_8980_NLP/blob/main/rcs1_TNLP_CSC_8980_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkhrxC02k2wi"
      },
      "source": [
        "### Rajath Chikkatur Srinivasa\n",
        "### 002552425"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YB4x8E4lB8L"
      },
      "source": [
        "# importing libraries\n",
        "import nltk, os\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import random\n",
        "from nltk.corpus import stopwords\n",
        "from IPython.display import clear_output\n",
        "from nltk.tokenize import word_tokenize  \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "# models\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "#sentiment analysis\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIS5Gk5AlD9f"
      },
      "source": [
        "# unzipping dataset\n",
        "!tar -xvf /content/drive/MyDrive/Projects/NLP/review_polarity.tar.gz\n",
        "clear_output()"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rnX7oDPk67u"
      },
      "source": [
        "1. Using NLTK tokenize all documents, separated by polarity, remove stop words, and list the top 20 most frequent tokens (and their counts) for the positive reviews, and the top 20 most frequent tokens (and their counts). What kind of things do you notice are different between the two sets? (30 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojtbIf-hw9Zw",
        "outputId": "57fe4bdc-0fd7-4794-9dc6-75c0d60fecc4"
      },
      "source": [
        "# collecting stopwords and punkts\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nAtpahJ0ZH7"
      },
      "source": [
        "pos_filepath = '/content/txt_sentoken/pos/'\n",
        "neg_filepath = '/content/txt_sentoken/neg/'\n",
        "pos_content = []\n",
        "neg_content = []"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV6a_X_g66JN"
      },
      "source": [
        "for i in os.listdir(pos_filepath):\n",
        "    file_content = open(os.path.join(pos_filepath,i), 'r').read()\n",
        "    pos_content.append(file_content)\n",
        "complete_pos_content = \" \".join(pos_content)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXcy0oQr6qjr"
      },
      "source": [
        "for i in os.listdir(neg_filepath):\n",
        "    file_content = open(os.path.join(neg_filepath,i), 'r').read()\n",
        "    neg_content.append(file_content)\n",
        "complete_neg_content = \" \".join(neg_content)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULOj8hZ49FaI"
      },
      "source": [
        "for i in pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBFfUhsT5gy5"
      },
      "source": [
        "#tokenizing positive\n",
        "pos_tokens = word_tokenize(complete_pos_content) \n",
        "#tokenizing negative\n",
        "neg_tokens = word_tokenize(complete_neg_content) "
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GXSk6h181L2"
      },
      "source": [
        "#remove stopwords from positive tokens\n",
        "rsw_pos_tokens = [word for word in pos_tokens if word.lower() not in stop_words]\n",
        "#remove stopwords from negative tokens\n",
        "rsw_neg_tokens = [word for word in neg_tokens if word.lower() not in stop_words]"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wIOaK6PD1Lk"
      },
      "source": [
        "p= defaultdict(int)\n",
        "for i in rsw_pos_tokens:\n",
        "    p[i]+=1\n",
        "n= defaultdict(int)\n",
        "for i in rsw_neg_tokens:\n",
        "    n[i]+=1"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dM_sOBLEN_W"
      },
      "source": [
        "pos_sort = sorted(p.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "neg_sort = sorted(n.items(), key=lambda x: x[1], reverse=True)[:20]"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QngIpR1U5hi0",
        "outputId": "c184960c-ab95-4659-e005-e3550388e9ce"
      },
      "source": [
        "print(\"top 20 most frequent tokens and their count for positive reviews are:\")\n",
        "for i in pos_sort:\n",
        "  print('token:', i[0], 'count:',i[1])"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top 20 most frequent tokens and their count for positive reviews are:\n",
            "token: , count: 42448\n",
            "token: . count: 33714\n",
            "token: 's count: 9473\n",
            "token: `` count: 8494\n",
            "token: ) count: 6039\n",
            "token: ( count: 6014\n",
            "token: film count: 5186\n",
            "token: one count: 2943\n",
            "token: n't count: 2775\n",
            "token: movie count: 2497\n",
            "token: like count: 1713\n",
            "token: ? count: 1570\n",
            "token: : count: 1502\n",
            "token: story count: 1231\n",
            "token: also count: 1200\n",
            "token: good count: 1190\n",
            "token: even count: 1175\n",
            "token: time count: 1171\n",
            "token: would count: 1079\n",
            "token: character count: 1067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGDh-EA1GD0X",
        "outputId": "1825c4d1-1e43-4bc4-a871-5b3c13ee1f89"
      },
      "source": [
        "print(\"top 20 most frequent tokens and their count for negative reviews are:\")\n",
        "for j in neg_sort:\n",
        "  print('token:', j[0], 'count:',j[1])"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top 20 most frequent tokens and their count for negative reviews are:\n",
            "token: , count: 35269\n",
            "token: . count: 32162\n",
            "token: `` count: 9123\n",
            "token: 's count: 8655\n",
            "token: ) count: 5742\n",
            "token: ( count: 5650\n",
            "token: film count: 4257\n",
            "token: n't count: 3442\n",
            "token: movie count: 3174\n",
            "token: one count: 2637\n",
            "token: ? count: 2201\n",
            "token: like count: 1832\n",
            "token: : count: 1540\n",
            "token: even count: 1381\n",
            "token: would count: 1185\n",
            "token: good count: 1126\n",
            "token: time count: 1111\n",
            "token: ! count: 1056\n",
            "token: get count: 1039\n",
            "token: bad count: 1019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru3B0iUkGW6I"
      },
      "source": [
        "* What kind of things do you notice are different between the two sets?\n",
        "- Firstly the sentiment terms count and the term itself is different. This is obvious. For example: good v/s bad\n",
        "- There are some positive tokens that are appearing the negative sentiment list like good.\n",
        "- The ordering of the terms are different. \n",
        "- There are some terms present in positive list but not in negative list and vice-versa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm9IFCKglxbv"
      },
      "source": [
        "2. Using the code from previous lectures, build 3 polarity classifiers using the following parameters (20 points). Note: just train the models.\\\n",
        "a) For training: use 50% of the positive dataset and 70% of the negative dataset. For your model use: NaiveBayes with the TF-IDF vectorizer.\\\n",
        "b) For training: use 50% of the negative dataset and 70% of the positive dataset. For your model use: NaiveBayes with the TF-IDF vectorizer.\\\n",
        "c) For training: use 25% of the negative dataset and 25% of the positive dataset. For your model use: SVM with the TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOiK54oRJTFm"
      },
      "source": [
        "a) For training: use 50% of the positive dataset and 70% of the negative dataset. For your model use: NaiveBayes with the TF-IDF vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwl_qh_LlyOL"
      },
      "source": [
        "random.shuffle(pos_content)\n",
        "random.shuffle(neg_content)\n",
        "pos_m1 = len(pos_content[:int((50/100)*len(pos_content))])\n",
        "neg_m1 = len(neg_content[:int((70/100)*len(neg_content))])\n",
        "m1_pos_train = pos_content[:pos_m1]\n",
        "m1_neg_train = neg_content[:neg_m1]\n",
        "m1_pos_test = pos_content[pos_m1:]\n",
        "m1_neg_test = neg_content[neg_m1:]"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PegRFQGGi9W",
        "outputId": "db00d202-ee7e-4294-9286-821c056bd757"
      },
      "source": [
        "m1_train_data = m1_pos_train + m1_neg_train\n",
        "m1_train_labels_1 = [1 for i in m1_pos_train]\n",
        "m1_train_labels_0 = [0 for i in m1_neg_train]\n",
        "m1_test_labels_1 = [1 for i in m1_pos_test]\n",
        "m1_test_labels_0 = [0 for i in m1_neg_test]\n",
        "m1_train_labels = m1_train_labels_1 + m1_train_labels_0 # 500-pos; 700-neg\n",
        "m1_test_labels = m1_test_labels_1 + m1_test_labels_0 # 500-pos; 300-neg\n",
        "#training NaiveBayes1\n",
        "model_nb_1 = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model_nb_1.fit(m1_train_data, m1_train_labels)\n",
        "# labels = model.predict(test.data)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidfvectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('multinomialnb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhRTGvQjJIth"
      },
      "source": [
        "b) For training: use 50% of the negative dataset and 70% of the positive dataset. For your model use: NaiveBayes with the TF-IDF vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8ZwLgaQcWa5"
      },
      "source": [
        "random.shuffle(pos_content)\n",
        "random.shuffle(neg_content)\n",
        "pos_m2 = len(pos_content[:int((70/100)*len(pos_content))])\n",
        "neg_m2 = len(neg_content[:int((50/100)*len(neg_content))])\n",
        "m2_pos_train = pos_content[:pos_m2]\n",
        "m2_neg_train = neg_content[:neg_m2]\n",
        "m2_pos_test = pos_content[pos_m2:]\n",
        "m2_neg_test = neg_content[neg_m2:]"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDYP3V30GkQ9",
        "outputId": "7727f8dd-cd9c-43da-be94-b718c6cb0fce"
      },
      "source": [
        "#training NaiveBayes2\n",
        "m2_train_data = m2_pos_train + m2_neg_train\n",
        "m2_train_labels_1 = [1 for i in m2_pos_train]\n",
        "m2_train_labels_0 = [0 for i in m2_neg_train]\n",
        "m2_test_labels_1 = [1 for i in m2_pos_test]\n",
        "m2_test_labels_0 = [0 for i in m2_neg_test]\n",
        "m2_train_labels = m2_train_labels_1 + m2_train_labels_0\n",
        "# m2_test_labels = m2_test_labels_1 + m2_test_labels_0\n",
        "model_nb_2 = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model_nb_2.fit(m2_train_data, m2_train_labels)\n",
        "# labels = model.predict(test.data)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidfvectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('multinomialnb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41cmoVOIJMPl"
      },
      "source": [
        "c) For training: use 25% of the negative dataset and 25% of the positive dataset. For your model use: SVM with the TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q00hWVtTck5_"
      },
      "source": [
        "random.shuffle(pos_content)\n",
        "random.shuffle(neg_content)\n",
        "pos_m3 = len(pos_content[:int((25/100)*len(pos_content))])\n",
        "neg_m3 = len(neg_content[:int((25/100)*len(neg_content))])\n",
        "m3_pos_train = pos_content[:pos_m3]\n",
        "m3_neg_train = neg_content[:neg_m3]\n",
        "m3_pos_test = pos_content[pos_m3:]\n",
        "m3_neg_test = neg_content[neg_m3:]"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWDbVINoIF7e",
        "outputId": "58edfe78-f2ae-466c-f72a-c60a3b3076e9"
      },
      "source": [
        "#training SVM\n",
        "m3_train_data = m3_pos_train + m3_neg_train\n",
        "m3_train_labels_1 = [1 for i in m3_pos_train]\n",
        "m3_train_labels_0 = [0 for i in m3_neg_train]\n",
        "m3_test_labels_1 = [1 for i in m3_pos_test]\n",
        "m3_test_labels_0 = [0 for i in m3_neg_test]\n",
        "m3_train_labels = m3_train_labels_1 + m3_train_labels_0\n",
        "m3_test_labels = m3_test_labels_1 + m3_test_labels_0\n",
        "model_svc_3 = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model_svc_3.fit(m3_train_data, m3_train_labels)\n",
        "# labels = model.predict(test.data)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidfvectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('multinomialnb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YgfGMhulyZa"
      },
      "source": [
        "3) Using the models from question 2, evaluate them on their individual rest of the dataset. This is, \\\n",
        "for a) 50% positive and 30% negative, \\\n",
        "for b) 50% negative and 30% positive, and \\\n",
        "for c) 75% negative and 75% positive. Calculate and show ONLY the following metrics for each model: Accuracy, Precision, Recall, Macro F1-score. (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6BEOQkTlysR"
      },
      "source": [
        "# printing performance metrics for model-1\n",
        "m1_name = 'NaiveBayes1-TfIdf'\n",
        "m1_pred = model_nb_1.predict(m1_pos_test+m1_neg_test)\n",
        "m1_accuracy = accuracy_score(m1_test_labels, m1_pred)\n",
        "m1_precision = precision_score(m1_test_labels, m1_pred)\n",
        "recall_model1 =  recall_score(m1_test_labels, m1_pred)\n",
        "mf1_model_1 =  f1_score(m1_pred, m1_test_labels, average='macro')\n",
        "m1_pvalues = [m1_name, m1_accuracy, m1_precision, recall_model1, mf1_model_1]\n",
        "# print('Mean Absolute Error:', mean_absolute_error(test.target,labels))\n",
        "# print('Mean Squared Error:', mean_squared_error(test.target, labels))  \n",
        "# print('Root Mean Squared Error:', np.sqrt(mean_squared_error(test.target, labels)))"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmOk07qeJjiq"
      },
      "source": [
        "# printing performance metrics for model-2\n",
        "m2_test_labels = m2_test_labels_1 + m2_test_labels_0\n",
        "m2_name = 'NaiveBayes2-TfIdf'\n",
        "m2_pred = model_nb_2.predict(m2_pos_test+m2_neg_test)\n",
        "m2_accuracy = accuracy_score(m2_test_labels,m2_pred)\n",
        "m2_precision = precision_score(m2_test_labels, m2_pred,m2_test_labels)\n",
        "recall_model2 =  recall_score(m2_test_labels,m2_pred)\n",
        "mf1_model_2 =  f1_score(m2_pred, m2_test_labels, average='macro')\n",
        "m2_pvalues = [m2_name, m2_accuracy, m2_precision, recall_model2, mf1_model_2]\n",
        "# print('Mean Absolute Error:', mean_absolute_error(test.target,labels))\n",
        "# print('Mean Squared Error:', mean_squared_error(test.target, labels))  \n",
        "# print('Root Mean Squared Error:', np.sqrt(mean_squared_error(test.target, labels)))"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGThnruoJqXn"
      },
      "source": [
        "# printing performance metrics for model-3\n",
        "m3_test_labels = m3_test_labels_1 + m3_test_labels_0\n",
        "m3_name = 'Support Vector Machine'\n",
        "m3_pred = model_svc_3.predict(m3_pos_test+m3_neg_test)\n",
        "m3_accuracy = accuracy_score(m3_test_labels, m3_pred)\n",
        "m3_precision = precision_score(m3_test_labels, m3_pred)\n",
        "recall_model3 =  recall_score(m3_test_labels, m3_pred)\n",
        "mf1_model_3 =  f1_score(m3_pred,m3_test_labels, average='macro')\n",
        "m3_pvalues = [m3_name, m3_accuracy, m3_precision, recall_model3, mf1_model_3]\n",
        "# print('Mean Absolute Error:', mean_absolute_error(test.target,labels))\n",
        "# print('Mean Squared Error:', mean_squared_error(test.target, labels))  \n",
        "# print('Root Mean Squared Error:', np.sqrt(mean_squared_error(test.target, labels)))"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "bLTFrNxXTKZP",
        "outputId": "f19dc277-8dce-430d-9dfb-a813ffdc00c7"
      },
      "source": [
        "#creating a dataframe for metrics of all models performance metrixs\n",
        "pm_list = [m3_pvalues, m2_pvalues, m1_pvalues]\n",
        "pm_df = pd.DataFrame(pm_list, columns = [\"model_name\", \"accuracy\", \"precison\", \"recall\", 'macro_f1_score'])\n",
        "pm_df"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precison</th>\n",
              "      <th>recall</th>\n",
              "      <th>macro_f1_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Support Vector Machine</td>\n",
              "      <td>0.781333</td>\n",
              "      <td>0.76375</td>\n",
              "      <td>0.814667</td>\n",
              "      <td>0.781090</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaiveBayes2-TfIdf</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.37500</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.272727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaiveBayes1-TfIdf</td>\n",
              "      <td>0.378750</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.006000</td>\n",
              "      <td>0.279437</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               model_name  accuracy  precison    recall  macro_f1_score\n",
              "0  Support Vector Machine  0.781333   0.76375  0.814667        0.781090\n",
              "1       NaiveBayes2-TfIdf  0.375000   0.37500  1.000000        0.272727\n",
              "2       NaiveBayes1-TfIdf  0.378750   1.00000  0.006000        0.279437"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVm25QQVly3q"
      },
      "source": [
        "4) Using the model performance metrics from question 3, answer the following questions. Please provide logical and intuitive rationale for your answers, simple answers like: because it has the best score, will not be sufficient. (40 points):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwW18z4nz1Y4"
      },
      "source": [
        "a) What is the best performing model?\\\n",
        "Support vector machines is the best performing model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehb01-O7z4dU"
      },
      "source": [
        "b) Why do you think this is the best performing model?\\\n",
        "The training set for the category of sentiments (positve and negative) in SVM is equally distributed that is well balanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Q5-iKTH0AWF"
      },
      "source": [
        "c) How does class imbalance play in determining polarity?\\\n",
        "Since model1 and model2 had class imbalances. It can be seen from the derived metrics for them that precision and recall respectively for each of them is calculated as 1 which is not an ideal scinario for a classification task. This is also reflected in their accuracy scores which is low. Over all, with respect to polarity - Model 1 and Model 2 , due to class imbalance, classifies their own polarity(higher percentage polarity dataset) correctly.  In this case, Negative(Precision-1 in model1) and Positive (Precision-1 in model2) respectively"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hpt_yMKc0Ccy"
      },
      "source": [
        "d) Do you think either more data or a better model is a better approach for this\n",
        "kind of task?\\\n",
        "More data does not always guarentee better performance/output. It is a blend of having the correct model with right amount of data. Sometimes a better performing model provides incorrect output due to improper balance in dataset. An hybrid model approach can be incorporated. Transformer models, Neural network based models can be trained to achieve "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud20FJI_lzXv"
      },
      "source": [
        "5) Using NLTK and VADER, calculate the sentiment score for all documents in the\n",
        "positive polarity. Calculate the polarity threshold needed (and reasonable) to have the majority of the document labels match. Do the same for the negative class. Provide the threshold needed, the reason why you think this threshold is reasonable, and the accuracy percentage (how many documents are correctly labeled using this threshold). (45 points):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3aX9zXDPhW-"
      },
      "source": [
        "sia = SIA()"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZtje6IUOMex"
      },
      "source": [
        "def get_scores(content, filename):\n",
        "    sia_scores = sia.polarity_scores(content)\n",
        "    \n",
        "    return pd.Series({\n",
        "        'filename': filename,\n",
        "        'compound': sia_scores['compound'],\n",
        "        'positive': sia_scores['pos'],\n",
        "        'neutral': sia_scores['neu'],\n",
        "        'negative': sia_scores['neg']\n",
        "    })"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKOxqYQ2lzsn"
      },
      "source": [
        "df_pos_scores = pd.DataFrame([])\n",
        "\n",
        "for i in os.listdir(pos_filepath):\n",
        "    file_content = open(os.path.join(pos_filepath,i), 'r').read()\n",
        "    df_1 = get_scores(file_content, i).to_frame().transpose()\n",
        "    for index, row in df_1.iterrows():\n",
        "      df_pos_scores = df_pos_scores.append({'file_name': row['filename'], 'compound': row['compound'],'positive': row['positive'], 'neutral': row['neutral'], 'negative': row['negative']}, ignore_index = True)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "n1j4X_2SpzHX",
        "outputId": "87796e21-4081-452c-ed3f-3196404b730b"
      },
      "source": [
        "print('The sentiment score for all documents in the positive polarity is saved in the below dataframe')\n",
        "df_pos_scores"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentiment score for all documents in the positive polarity is saved in the below dataframe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>compound</th>\n",
              "      <th>file_name</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9931</td>\n",
              "      <td>cv815_22456.txt</td>\n",
              "      <td>0.104</td>\n",
              "      <td>0.736</td>\n",
              "      <td>0.160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9996</td>\n",
              "      <td>cv274_25253.txt</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.713</td>\n",
              "      <td>0.204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9210</td>\n",
              "      <td>cv927_10681.txt</td>\n",
              "      <td>0.069</td>\n",
              "      <td>0.852</td>\n",
              "      <td>0.079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.9993</td>\n",
              "      <td>cv442_13846.txt</td>\n",
              "      <td>0.199</td>\n",
              "      <td>0.684</td>\n",
              "      <td>0.117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9973</td>\n",
              "      <td>cv551_10565.txt</td>\n",
              "      <td>0.087</td>\n",
              "      <td>0.753</td>\n",
              "      <td>0.160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-0.9568</td>\n",
              "      <td>cv117_24295.txt</td>\n",
              "      <td>0.169</td>\n",
              "      <td>0.674</td>\n",
              "      <td>0.157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>-0.9861</td>\n",
              "      <td>cv602_8300.txt</td>\n",
              "      <td>0.100</td>\n",
              "      <td>0.848</td>\n",
              "      <td>0.052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0.9960</td>\n",
              "      <td>cv560_17175.txt</td>\n",
              "      <td>0.107</td>\n",
              "      <td>0.759</td>\n",
              "      <td>0.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>-0.9181</td>\n",
              "      <td>cv891_6385.txt</td>\n",
              "      <td>0.120</td>\n",
              "      <td>0.771</td>\n",
              "      <td>0.109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0.9880</td>\n",
              "      <td>cv677_17715.txt</td>\n",
              "      <td>0.101</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.127</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     compound        file_name  negative  neutral  positive\n",
              "0      0.9931  cv815_22456.txt     0.104    0.736     0.160\n",
              "1      0.9996  cv274_25253.txt     0.083    0.713     0.204\n",
              "2      0.9210  cv927_10681.txt     0.069    0.852     0.079\n",
              "3     -0.9993  cv442_13846.txt     0.199    0.684     0.117\n",
              "4      0.9973  cv551_10565.txt     0.087    0.753     0.160\n",
              "..        ...              ...       ...      ...       ...\n",
              "995   -0.9568  cv117_24295.txt     0.169    0.674     0.157\n",
              "996   -0.9861   cv602_8300.txt     0.100    0.848     0.052\n",
              "997    0.9960  cv560_17175.txt     0.107    0.759     0.134\n",
              "998   -0.9181   cv891_6385.txt     0.120    0.771     0.109\n",
              "999    0.9880  cv677_17715.txt     0.101    0.772     0.127\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCI9v-9zD2me"
      },
      "source": [
        "df_neg_scores = pd.DataFrame([])\n",
        "\n",
        "for i in os.listdir(neg_filepath):\n",
        "    file_content = open(os.path.join(neg_filepath,i), 'r').read()\n",
        "    df_2 = get_scores(file_content, i).to_frame().transpose()\n",
        "    for index, row in df_2.iterrows():\n",
        "      df_neg_scores = df_neg_scores.append({'file_name': row['filename'], 'compound': row['compound'],'positive': row['positive'], 'neutral': row['neutral'], 'negative': row['negative']}, ignore_index = True)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "uEMJeyBaD2xM",
        "outputId": "0baa2da9-41d8-4cb2-aee3-6fa7fa8bf184"
      },
      "source": [
        "print('The sentiment score for all documents in the negative polarity is saved in the below dataframe')\n",
        "df_neg_scores"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The sentiment score for all documents in the negative polarity is saved in the below dataframe\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>compound</th>\n",
              "      <th>file_name</th>\n",
              "      <th>negative</th>\n",
              "      <th>neutral</th>\n",
              "      <th>positive</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.8243</td>\n",
              "      <td>cv561_9484.txt</td>\n",
              "      <td>0.109</td>\n",
              "      <td>0.798</td>\n",
              "      <td>0.093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9932</td>\n",
              "      <td>cv135_12506.txt</td>\n",
              "      <td>0.083</td>\n",
              "      <td>0.755</td>\n",
              "      <td>0.161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.5106</td>\n",
              "      <td>cv568_17065.txt</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.772</td>\n",
              "      <td>0.112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.6371</td>\n",
              "      <td>cv297_10104.txt</td>\n",
              "      <td>0.134</td>\n",
              "      <td>0.732</td>\n",
              "      <td>0.135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9387</td>\n",
              "      <td>cv523_18285.txt</td>\n",
              "      <td>0.067</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>-0.9766</td>\n",
              "      <td>cv323_29633.txt</td>\n",
              "      <td>0.146</td>\n",
              "      <td>0.729</td>\n",
              "      <td>0.125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0.9981</td>\n",
              "      <td>cv574_23191.txt</td>\n",
              "      <td>0.096</td>\n",
              "      <td>0.735</td>\n",
              "      <td>0.169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>0.8535</td>\n",
              "      <td>cv385_29621.txt</td>\n",
              "      <td>0.108</td>\n",
              "      <td>0.758</td>\n",
              "      <td>0.134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>0.9793</td>\n",
              "      <td>cv936_17473.txt</td>\n",
              "      <td>0.113</td>\n",
              "      <td>0.731</td>\n",
              "      <td>0.156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>0.9223</td>\n",
              "      <td>cv396_19127.txt</td>\n",
              "      <td>0.144</td>\n",
              "      <td>0.660</td>\n",
              "      <td>0.197</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     compound        file_name  negative  neutral  positive\n",
              "0     -0.8243   cv561_9484.txt     0.109    0.798     0.093\n",
              "1      0.9932  cv135_12506.txt     0.083    0.755     0.161\n",
              "2     -0.5106  cv568_17065.txt     0.116    0.772     0.112\n",
              "3     -0.6371  cv297_10104.txt     0.134    0.732     0.135\n",
              "4      0.9387  cv523_18285.txt     0.067    0.833     0.100\n",
              "..        ...              ...       ...      ...       ...\n",
              "995   -0.9766  cv323_29633.txt     0.146    0.729     0.125\n",
              "996    0.9981  cv574_23191.txt     0.096    0.735     0.169\n",
              "997    0.8535  cv385_29621.txt     0.108    0.758     0.134\n",
              "998    0.9793  cv936_17473.txt     0.113    0.731     0.156\n",
              "999    0.9223  cv396_19127.txt     0.144    0.660     0.197\n",
              "\n",
              "[1000 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vdYOtZWmh8O"
      },
      "source": [
        "Bonus (40 points): Repeat questions 2,3 and 4 removing all stopwords. Answer the\n",
        "following questions: Did this change the results in any way? Why do you think so?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xm3e_bUmlTh"
      },
      "source": [
        "pos_content_bonus = []\n",
        "# removing stop words for positive review\n",
        "# rsw_pos_tokens = [word for word in pos_tokens if word.lower() not in stop_words]\n",
        "for i in pos_content:\n",
        "  sw_tokens_pos = []\n",
        "  doc_tokens = nltk.word_tokenize(i)\n",
        "  for token in doc_tokens:\n",
        "    if token not in stop_words:\n",
        "      sw_tokens_pos.append(token)\n",
        "  pos_content_bonus.append(' '.join(sw_tokens_pos))"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCBBBsv4FrI1"
      },
      "source": [
        "neg_content_bonus = []\n",
        "# removing stop words for positive review\n",
        "# rsw_pos_tokens = [word for word in pos_tokens if word.lower() not in stop_words]\n",
        "for i in neg_content:\n",
        "  sw_tokens_neg = []\n",
        "  doc_tokens = nltk.word_tokenize(i)\n",
        "  for token in doc_tokens:\n",
        "    if token not in stop_words:\n",
        "      sw_tokens_neg.append(token)\n",
        "  neg_content_bonus.append(' '.join(sw_tokens_neg))"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZA5A-dZ8BCY"
      },
      "source": [
        "a) For training: use 50% of the positive dataset and 70% of the negative dataset. For your model use: NaiveBayes with the TF-IDF vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSxuYnXetHi9"
      },
      "source": [
        "random.shuffle(pos_content_bonus)\n",
        "random.shuffle(neg_content_bonus)\n",
        "\n",
        "m1_pos_train = pos_content_bonus[:len(pos_content_bonus[:int((50/100)*len(pos_content_bonus))])]\n",
        "m1_neg_train = neg_content_bonus[:len(neg_content_bonus[:int((70/100)*len(neg_content_bonus))])]\n",
        "m1_pos_test = pos_content_bonus[len(pos_content_bonus[:int((50/100)*len(pos_content_bonus))]):]\n",
        "m1_neg_test = neg_content_bonus[len(neg_content_bonus[:int((70/100)*len(neg_content_bonus))]):]"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgSuxajktP1Z",
        "outputId": "9eb49822-ac35-452b-cb75-f7928b5bb4fa"
      },
      "source": [
        "m1_train_data = m1_pos_train + m1_neg_train\n",
        "m1_train_labels_1 = [1 for i in m1_pos_train]\n",
        "m1_train_labels_0 = [0 for i in m1_neg_train]\n",
        "m1_test_labels_1 = [1 for i in m1_pos_test]\n",
        "m1_test_labels_0 = [0 for i in m1_neg_test]\n",
        "m1_train_labels = m1_train_labels_1 + m1_train_labels_0 # 500-pos; 700-neg\n",
        "m1_test_labels = m1_test_labels_1 + m1_test_labels_0 # 500-pos; 300-neg\n",
        "#training NaiveBayes1\n",
        "model_nb_1 = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model_nb_1.fit(m1_train_data, m1_train_labels)\n",
        "# labels = model.predict(test.data)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidfvectorizer',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('multinomialnb',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtHJ_0oeJWo6"
      },
      "source": [
        "b) For training: use 50% of the negative dataset and 70% of the positive dataset. For your model use: NaiveBayes with the TF-IDF vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PU5BJKBJRuK"
      },
      "source": [
        "random.shuffle(pos_content_bonus)\n",
        "random.shuffle(neg_content_bonus)\n",
        "m1_pos_train = pos_content_bonus[:len(pos_content_bonus[:int((70/100)*len(pos_content_bonus))])]\n",
        "m1_neg_train = neg_content_bonus[:len(neg_content_bonus[:int((50/100)*len(neg_content_bonus))])]\n",
        "m1_pos_test = pos_content_bonus[len(pos_content_bonus[:int((70/100)*len(pos_content_bonus))]):]\n",
        "m1_neg_test = neg_content_bonus[len(neg_content_bonus[:int((50/100)*len(neg_content_bonus))]):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwfuwqlLJU7T"
      },
      "source": [
        "m1_train_data = m1_pos_train + m1_neg_train\n",
        "m1_train_labels_1 = [1 for i in m1_pos_train]\n",
        "m1_train_labels_0 = [0 for i in m1_neg_train]\n",
        "m1_test_labels_1 = [1 for i in m1_pos_test]\n",
        "m1_test_labels_0 = [0 for i in m1_neg_test]\n",
        "m1_train_labels = m1_train_labels_1 + m1_train_labels_0 # 500-pos; 700-neg\n",
        "m1_test_labels = m1_test_labels_1 + m1_test_labels_0 # 500-pos; 300-neg\n",
        "#training NaiveBayes1\n",
        "model_nb_1 = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model_nb_1.fit(m1_train_data, m1_train_labels)\n",
        "# labels = model.predict(test.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vCuC3-IMTdQ"
      },
      "source": [
        "c) For training: use 25% of the negative dataset and 25% of the positive dataset. For your model use: SVM with the TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ub_kUgSFMXLZ"
      },
      "source": [
        "random.shuffle(pos_content_bonus)\n",
        "random.shuffle(neg_content_bonus)\n",
        "m1_pos_train = pos_content_bonus[:len(pos_content_bonus[:int((25/100)*len(pos_content_bonus))])]\n",
        "m1_neg_train = neg_content_bonus[:len(neg_content_bonus[:int((25/100)*len(neg_content_bonus))])]\n",
        "m1_pos_test = pos_content_bonus[len(pos_content_bonus[:int((25/100)*len(pos_content_bonus))]):]\n",
        "m1_neg_test = neg_content_bonus[len(neg_content_bonus[:int((25/100)*len(neg_content_bonus))]):]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbsN-oJ2MXYw"
      },
      "source": [
        "m1_train_data = m1_pos_train + m1_neg_train\n",
        "m1_train_labels_1 = [1 for i in m1_pos_train]\n",
        "m1_train_labels_0 = [0 for i in m1_neg_train]\n",
        "m1_test_labels_1 = [1 for i in m1_pos_test]\n",
        "m1_test_labels_0 = [0 for i in m1_neg_test]\n",
        "m1_train_labels = m1_train_labels_1 + m1_train_labels_0 # 500-pos; 700-neg\n",
        "m1_test_labels = m1_test_labels_1 + m1_test_labels_0 # 500-pos; 300-neg\n",
        "#training NaiveBayes1\n",
        "model_nb_1 = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
        "model_nb_1.fit(m1_train_data, m1_train_labels)\n",
        "# labels = model.predict(test.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLUwH1NJq-TP"
      },
      "source": [
        "a) What is the best performing model?\n",
        "Support vector machines is the best performing model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGwthHX2rC4r"
      },
      "source": [
        "b) Why do you think this is the best performing model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2q_E2A6r4fX"
      },
      "source": [
        "c) How does class imbalance play in determining polarity?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZM5a_lADr6oP"
      },
      "source": [
        "d) Do you think either more data or a better model is a better approach for this kind of task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzC-yuNQqktD"
      },
      "source": [
        "Did this change the results in any way? Why do you think so?"
      ]
    }
  ]
}