{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rcs1_TNLP_CSC_8980_HW3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1a1MwRe-7gPTcOGw2MLnjCVjla1Kqlk2j",
      "authorship_tag": "ABX9TyOvVrKrLOm0s/rVGZ6wQtRy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csrajath/CSC_8980_NLP/blob/main/rcs1_TNLP_CSC_8980_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkhrxC02k2wi"
      },
      "source": [
        "### Rajath Chikkatur Srinivasa\n",
        "### 002552425"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YB4x8E4lB8L"
      },
      "source": [
        "# importing libraries\n",
        "import nltk, os\n",
        "from collections import defaultdict\n",
        "from nltk.corpus import stopwords\n",
        "from IPython.display import clear_output\n",
        "from nltk.tokenize import word_tokenize  \n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# models\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "#sentiment analysis\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIS5Gk5AlD9f"
      },
      "source": [
        "# unzipping dataset\n",
        "!tar -xvf /content/drive/MyDrive/Projects/NLP/review_polarity.tar.gz\n",
        "clear_output()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rnX7oDPk67u"
      },
      "source": [
        "1. Using NLTK tokenize all documents, separated by polarity, remove stop words, and list the top 20 most frequent tokens (and their counts) for the positive reviews, and the top 20 most frequent tokens (and their counts). What kind of things do you notice are different between the two sets? (30 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ojtbIf-hw9Zw",
        "outputId": "6ec81b44-86ae-4b88-cc64-704942f0e3cb"
      },
      "source": [
        "# collecting stopwords and punkts\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nAtpahJ0ZH7"
      },
      "source": [
        "pos_filepath = '/content/txt_sentoken/pos/'\n",
        "neg_filepath = '/content/txt_sentoken/neg/'\n",
        "pos_content = []\n",
        "neg_content = []"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV6a_X_g66JN"
      },
      "source": [
        "for i in os.listdir(pos_filepath):\n",
        "    file_content = open(os.path.join(pos_filepath,i), 'r').read()\n",
        "    pos_content.append(file_content)\n",
        "complete_pos_content = \" \".join(pos_content)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXcy0oQr6qjr"
      },
      "source": [
        "for i in os.listdir(neg_filepath):\n",
        "    file_content = open(os.path.join(neg_filepath,i), 'r').read()\n",
        "    neg_content.append(file_content)\n",
        "complete_neg_content = \" \".join(neg_content)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBFfUhsT5gy5"
      },
      "source": [
        "#tokenizing positive\n",
        "pos_tokens = word_tokenize(complete_pos_content) \n",
        "#tokenizing negative\n",
        "neg_tokens = word_tokenize(complete_neg_content) "
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GXSk6h181L2"
      },
      "source": [
        "#remove stopwords from positive tokens\n",
        "rsw_pos_tokens = [word for word in pos_tokens if word.lower() not in stop_words]\n",
        "#remove stopwords from negative tokens\n",
        "rsw_neg_tokens = [word for word in neg_tokens if word.lower() not in stop_words]"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wIOaK6PD1Lk"
      },
      "source": [
        "p= defaultdict(int)\n",
        "for i in rsw_pos_tokens:\n",
        "    p[i]+=1\n",
        "n= defaultdict(int)\n",
        "for i in rsw_neg_tokens:\n",
        "    n[i]+=1"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dM_sOBLEN_W"
      },
      "source": [
        "pos_sort = sorted(p.items(), key=lambda x: x[1], reverse=True)[:20]\n",
        "neg_sort = sorted(n.items(), key=lambda x: x[1], reverse=True)[:20]"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QngIpR1U5hi0",
        "outputId": "36bff994-06e5-4f9b-bbc2-53a6a566e8aa"
      },
      "source": [
        "print(\"top 20 most frequent tokens and their count for positive reviews are:\")\n",
        "for i in pos_sort:\n",
        "  print('token:', i[0], 'count:',i[1])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top 20 most frequent tokens and their count for positive reviews are:\n",
            "token: , count: 42448\n",
            "token: . count: 33714\n",
            "token: 's count: 9473\n",
            "token: `` count: 8494\n",
            "token: ) count: 6039\n",
            "token: ( count: 6014\n",
            "token: film count: 5186\n",
            "token: one count: 2943\n",
            "token: n't count: 2775\n",
            "token: movie count: 2497\n",
            "token: like count: 1713\n",
            "token: ? count: 1570\n",
            "token: : count: 1502\n",
            "token: story count: 1231\n",
            "token: also count: 1200\n",
            "token: good count: 1190\n",
            "token: even count: 1175\n",
            "token: time count: 1171\n",
            "token: would count: 1079\n",
            "token: character count: 1067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGDh-EA1GD0X",
        "outputId": "1c14243a-578b-435e-f4f4-20e1199aa86c"
      },
      "source": [
        "print(\"top 20 most frequent tokens and their count for negative reviews are:\")\n",
        "for j in neg_sort:\n",
        "  print('token:', j[0], 'count:',j[1])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top 20 most frequent tokens and their count for negative reviews are:\n",
            "token: , count: 35269\n",
            "token: . count: 32162\n",
            "token: `` count: 9123\n",
            "token: 's count: 8655\n",
            "token: ) count: 5742\n",
            "token: ( count: 5650\n",
            "token: film count: 4257\n",
            "token: n't count: 3442\n",
            "token: movie count: 3174\n",
            "token: one count: 2637\n",
            "token: ? count: 2201\n",
            "token: like count: 1832\n",
            "token: : count: 1540\n",
            "token: even count: 1381\n",
            "token: would count: 1185\n",
            "token: good count: 1126\n",
            "token: time count: 1111\n",
            "token: ! count: 1056\n",
            "token: get count: 1039\n",
            "token: bad count: 1019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru3B0iUkGW6I"
      },
      "source": [
        "* What kind of things do you notice are different between the two sets?\n",
        "- Firstly the sentiment terms count and the term itself is different. This is obvious. For example: good v/s bad\n",
        "- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQDuIGroxPpi"
      },
      "source": [
        "# removing stop words\n",
        "# remove_stopwords = [word for word in remove_punctuation.split() if word.lower() not in stopwords.words('english')]\n",
        "# remove_stopwords = ' '.join(remove_stopwords)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm9IFCKglxbv"
      },
      "source": [
        "2. Using the code from previous lectures, build 3 polarity classifiers using the following parameters (20 points). Note: just train the models.\\\n",
        "a) For training: use 50% of the positive dataset and 70% of the negative dataset. For your model use: NaiveBayes with the TF-IDF vectorizer.\\\n",
        "b) For training: use 50% of the negative dataset and 70% of the positive dataset. For your model use: NaiveBayes with the TF-IDF vectorizer.\\\n",
        "c) For training: use 25% of the negative dataset and 25% of the positive dataset. For your model use: SVM with the TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwl_qh_LlyOL"
      },
      "source": [
        "# polarity classifier models\n",
        "#pcm1\n",
        "\n",
        "pcm1 = True\n",
        "#pcm2\n",
        "\n",
        "pcm2 = True\n",
        "\n",
        "#pcm3\n",
        "\n",
        "pcm3 = True"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YgfGMhulyZa"
      },
      "source": [
        "Using the models from question 2, evaluate them on their individual rest of the dataset. This is, \\\n",
        "for a) 50% positive and 30% negative, \\\n",
        "for b) 50% negative and 30% positive, and \\\n",
        "for c) 75% negative and 75% positive. Calculate and show ONLY the following metrics for each model: Accuracy, Precision, Recall, Macro F1-score. (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6BEOQkTlysR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVm25QQVly3q"
      },
      "source": [
        "4) Using the model performance metrics from question 3, answer the following questions. Please provide logical and intuitive rationale for your answers, simple answers like: because it has the best score, will not be sufficient. (40 points):\\\n",
        "a) What is the best performing model?\\\n",
        "b) Why do you think this is the best performing model?\\\n",
        "c) How does class imbalance play in determining polarity?\\\n",
        "d) Do you think either more data or a better model is a better approach for this\n",
        "kind of task?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrKQTZeUlzMr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud20FJI_lzXv"
      },
      "source": [
        "5) Using NLTK and VADER, calculate the sentiment score for all documents in the\n",
        "positive polarity. Calculate the polarity threshold needed (and reasonable) to have the majority of the document labels match. Do the same for the negative class. Provide the threshold needed, the reason why you think this threshold is reasonable, and the accuracy percentage (how many documents are correctly labeled using this threshold). (45 points):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKOxqYQ2lzsn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vdYOtZWmh8O"
      },
      "source": [
        "Bonus (40 points): Repeat questions 2,3 and 4 removing all stopwords. Answer the\n",
        "following questions: Did this change the results in any way? Why do you think so?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xm3e_bUmlTh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}