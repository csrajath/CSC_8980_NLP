{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rcs1_TNLP_CSC_8980_HW3.ipynb",
      "provenance": [],
      "mount_file_id": "1a1MwRe-7gPTcOGw2MLnjCVjla1Kqlk2j",
      "authorship_tag": "ABX9TyPL5V02b6B1X+xeulkEmred",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/csrajath/CSC_8980_NLP/blob/main/rcs1_TNLP_CSC_8980_HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkhrxC02k2wi"
      },
      "source": [
        "### Rajath Chikkatur Srinivasa\n",
        "### 002552425"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YB4x8E4lB8L"
      },
      "source": [
        "# importing libraries\n",
        "from IPython.display import clear_output"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIS5Gk5AlD9f"
      },
      "source": [
        "# unzipping dataset\n",
        "!tar -xvf /content/drive/MyDrive/Projects/NLP/review_polarity.tar.gz\n",
        "clear_output()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rnX7oDPk67u"
      },
      "source": [
        "1. Using NLTK tokenize all documents, separated by polarity, remove stop words, and list the top 20 most frequent tokens (and their counts) for the positive reviews, and the top 20 most frequent tokens (and their counts). What kind of things do you notice are different between the two sets? (30 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-tBmS80lAyJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm9IFCKglxbv"
      },
      "source": [
        "2. Using the code from previous lectures, build 3 polarity classifiers using the following parameters (20 points). Note: just train the models.\n",
        "a) For training: use 50% of the positive dataset and 70% of the negative dataset. For your model use: NaiveBayes with the TF-IDF vectorizer.\n",
        "b) For training: use 50% of the negative dataset and 70% of the positive dataset. For your model use: NaiveBayes with the TF-IDF vectorizer.\n",
        "c) For training: use 25% of the negative dataset and 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwl_qh_LlyOL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YgfGMhulyZa"
      },
      "source": [
        "Using the models from question 2, evaluate them on their individual rest of the dataset. This is, \\\n",
        "for a) 50% positive and 30% negative, \\\n",
        "for b) 50% negative and 30% positive, and \\\n",
        "for c) 75% negative and 75% positive. Calculate and show ONLY the following metrics for each model: Accuracy, Precision, Recall, Macro F1-score. (15 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6BEOQkTlysR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVm25QQVly3q"
      },
      "source": [
        "4) Using the model performance metrics from question 3, answer the following questions. Please provide logical and intuitive rationale for your answers, simple answers like: because it has the best score, will not be sufficient. (40 points):\\\n",
        "a) What is the best performing model?\\\n",
        "b) Why do you think this is the best performing model?\\\n",
        "c) How does class imbalance play in determining polarity?\\\n",
        "d) Do you think either more data or a better model is a better approach for this\n",
        "kind of task?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrKQTZeUlzMr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud20FJI_lzXv"
      },
      "source": [
        "5) Using NLTK and VADER, calculate the sentiment score for all documents in the\n",
        "positive polarity. Calculate the polarity threshold needed (and reasonable) to have the majority of the document labels match. Do the same for the negative class. Provide the threshold needed, the reason why you think this threshold is reasonable, and the accuracy percentage (how many documents are correctly labeled using this threshold). (45 points):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKOxqYQ2lzsn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vdYOtZWmh8O"
      },
      "source": [
        "Bonus (40 points): Repeat questions 2,3 and 4 removing all stopwords. Answer the\n",
        "following questions: Did this change the results in any way? Why do you think so?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xm3e_bUmlTh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}